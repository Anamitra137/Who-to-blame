File,Commit,Author,Commit Message,Start Line,End Line,Previous Author,Previous Commit,Keyword Label,Commit Date,Previous Commit Date
tests/conftest.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",1,14,,,1,2023-03-06 22:00:49,
LICENSE,6e3be77,Jong Wook Kim,initial commit,1,21,,,0,2022-09-21 16:09:43,
pyproject.toml,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",48,54,,,1,2023-03-06 23:50:37,
pyproject.toml,dd4d010,Christian Clauss,PEP 621: Migrate from setup.py to pyproject.toml (#2435),1,47,Jong Wook Kim,b80bcf6,0,2025-01-04 09:38:35,2023-03-06 23:50:37
notebooks/LibriSpeech.ipynb,6e3be77,Jong Wook Kim,initial commit,1,958,,,0,2022-09-21 16:09:43,
MANIFEST.in,6e3be77,Jong Wook Kim,initial commit,5,5,,,0,2022-09-21 16:09:43,
MANIFEST.in,b9f9b43,Romain Beaumont,"Add github action to automatically push to pypi on Release x.y.z commit (#681)  * Add github action to automatically push to pypi on Release x.y.z commit  * some housekeeping for pypi upload  * add version.py  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",1,3,Jong Wook Kim,6e3be77,0,2023-01-17 23:50:26,2022-09-21 16:09:43
MANIFEST.in,6e3be77,Jong Wook Kim,initial commit,4,4,,,0,2022-09-21 16:09:43,
data/meanwhile.json,6e3be77,Jong Wook Kim,initial commit,1,322,,,0,2022-09-21 16:09:43,
tests/test_timing.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",3,7,,,1,2023-03-06 22:00:49,
tests/test_timing.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",15,18,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
tests/test_timing.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",8,8,,,1,2023-03-06 22:00:49,
tests/test_timing.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",2,2,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
tests/test_timing.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",1,1,,,1,2023-03-06 22:00:49,
tests/test_timing.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",9,12,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
tests/test_timing.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",13,14,,,1,2023-03-06 22:00:49,
tests/test_timing.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",19,75,,,1,2023-03-06 22:00:49,
tests/test_timing.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",76,81,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
tests/test_timing.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",82,96,,,1,2023-03-06 22:00:49,
tests/test_audio.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",5,5,Jong Wook Kim,6e3be77,1,2023-03-06 23:50:37,2022-09-21 16:09:43
tests/test_audio.py,6e3be77,Jong Wook Kim,initial commit,6,19,,,0,2022-09-21 16:09:43,
tests/test_audio.py,6e3be77,Jong Wook Kim,initial commit,1,4,,,0,2022-09-21 16:09:43,
tests/test_normalizer.py,6e3be77,Jong Wook Kim,initial commit,8,89,,,0,2022-09-21 16:09:43,
tests/test_normalizer.py,ea1c266,Markus Hennerbichler,Fix bug where mm is mistakenly replaced with hmm in e.g. 20mm (#659)  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>,90,90,Jong Wook Kim,6e3be77,1,2023-01-18 18:41:11,2022-09-21 16:09:43
tests/test_normalizer.py,6e3be77,Jong Wook Kim,initial commit,91,96,,,0,2022-09-21 16:09:43,
tests/test_normalizer.py,6e3be77,Jong Wook Kim,initial commit,1,3,,,0,2022-09-21 16:09:43,
tests/test_normalizer.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",4,7,Markus Hennerbichler,ea1c266,1,2023-03-06 23:50:37,2023-01-18 18:41:11
whisper/assets/mel_filters.npz,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1,16,,,1,2023-11-06 18:10:30,
tests/test_tokenizer.py,6e3be77,Jong Wook Kim,initial commit,15,24,,,0,2022-09-21 16:09:43,
tests/test_tokenizer.py,746aaae,Jong Wook Kim,remove tiktoken pin (#1759),6,14,Guillaume Klein,5f9ac65,0,2023-11-06 11:05:21,2023-03-14 16:32:41
tests/test_tokenizer.py,746aaae,Jong Wook Kim,remove tiktoken pin (#1759),1,2,Guillaume Klein,5f9ac65,0,2023-11-06 11:05:21,2023-03-14 16:32:41
tests/test_tokenizer.py,6e3be77,Jong Wook Kim,initial commit,3,5,,,0,2022-09-21 16:09:43,
tests/test_tokenizer.py,5f9ac65,Guillaume Klein,Fix truncated words list when the replacement character is decoded (#1089),25,32,,,1,2023-03-14 16:32:41,
tests/test_tokenizer.py,746aaae,Jong Wook Kim,remove tiktoken pin (#1759),33,33,Guillaume Klein,5f9ac65,0,2023-11-06 11:05:21,2023-03-14 16:32:41
tests/test_tokenizer.py,5f9ac65,Guillaume Klein,Fix truncated words list when the replacement character is decoded (#1089),34,34,,,1,2023-03-14 16:32:41,
whisper/assets/gpt2.tiktoken,839639a,Jong Wook Kim,"Use tiktoken (#1044)  * use tiktoken==0.3.0  * formatting  * tuple should be safer  * Update whisper/tokenizer.py  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>  * use tiktoken 0.3.1  * reflecting suggestions  * cleanup  * bypassing load_tiktoken_bpe to avoid blobfile dep  ---------  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>",1,50256,,,0,2023-03-13 09:34:16,
whisper/assets/multilingual.tiktoken,839639a,Jong Wook Kim,"Use tiktoken (#1044)  * use tiktoken==0.3.0  * formatting  * tuple should be safer  * Update whisper/tokenizer.py  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>  * use tiktoken 0.3.1  * reflecting suggestions  * cleanup  * bypassing load_tiktoken_bpe to avoid blobfile dep  ---------  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>",1,50257,,,0,2023-03-13 09:34:16,
tests/test_transcribe.py,6e3be77,Jong Wook Kim,initial commit,8,9,,,0,2022-09-21 16:09:43,
tests/test_transcribe.py,6e3be77,Jong Wook Kim,initial commit,5,6,,,0,2022-09-21 16:09:43,
tests/test_transcribe.py,b1d213c,Jong Wook Kim,allow test_transcribe to run on CPU when CUDA is not available,4,4,Jong Wook Kim,6e3be77,0,2023-01-17 21:43:36,2022-09-21 16:09:43
tests/test_transcribe.py,6e3be77,Jong Wook Kim,initial commit,11,11,,,0,2022-09-21 16:09:43,
tests/test_transcribe.py,6e3be77,Jong Wook Kim,initial commit,1,3,,,0,2022-09-21 16:09:43,
tests/test_transcribe.py,b1d213c,Jong Wook Kim,allow test_transcribe to run on CPU when CUDA is not available,12,13,Jong Wook Kim,6e3be77,0,2023-01-17 21:43:36,2022-09-21 16:09:43
tests/test_transcribe.py,839639a,Jong Wook Kim,"Use tiktoken (#1044)  * use tiktoken==0.3.0  * formatting  * tuple should be safer  * Update whisper/tokenizer.py  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>  * use tiktoken 0.3.1  * reflecting suggestions  * cleanup  * bypassing load_tiktoken_bpe to avoid blobfile dep  ---------  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>",7,7,Jong Wook Kim,38f2f4d,0,2023-03-13 09:34:16,2023-03-08 23:34:07
tests/test_transcribe.py,b1d213c,Jong Wook Kim,allow test_transcribe to run on CPU when CUDA is not available,10,10,Jong Wook Kim,6e3be77,0,2023-01-17 21:43:36,2022-09-21 16:09:43
tests/test_transcribe.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",17,19,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
tests/test_transcribe.py,6e3be77,Jong Wook Kim,initial commit,14,16,,,0,2022-09-21 16:09:43,
tests/test_transcribe.py,38f2f4d,Jong Wook Kim,fix all_tokens handling that caused more repetitions and discrepancy in JSON (#1060),21,21,Jong Wook Kim,b80bcf6,1,2023-03-08 23:34:07,2023-03-06 23:50:37
tests/test_transcribe.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",27,27,Jong Wook Kim,b1d213c,1,2023-03-06 22:00:49,2023-01-17 21:43:36
tests/test_transcribe.py,6e3be77,Jong Wook Kim,initial commit,20,20,,,0,2022-09-21 16:09:43,
tests/test_transcribe.py,6e3be77,Jong Wook Kim,initial commit,22,26,,,0,2022-09-21 16:09:43,
tests/test_transcribe.py,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",28,28,Jong Wook Kim,839639a,1,2023-11-06 18:10:30,2023-03-13 09:34:16
tests/test_transcribe.py,839639a,Jong Wook Kim,"Use tiktoken (#1044)  * use tiktoken==0.3.0  * formatting  * tuple should be safer  * Update whisper/tokenizer.py  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>  * use tiktoken 0.3.1  * reflecting suggestions  * cleanup  * bypassing load_tiktoken_bpe to avoid blobfile dep  ---------  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>",29,32,Jong Wook Kim,38f2f4d,0,2023-03-13 09:34:16,2023-03-08 23:34:07
tests/test_transcribe.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",33,39,Jong Wook Kim,b1d213c,1,2023-03-06 22:00:49,2023-01-17 21:43:36
tests/test_transcribe.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",40,42,,,1,2023-03-06 22:00:49,
whisper/normalizers/english.json,6e3be77,Jong Wook Kim,initial commit,1,1739,,,0,2022-09-21 16:09:43,
whisper/normalizers/english.json,6e3be77,Jong Wook Kim,initial commit,1740,1741,,,0,2022-09-21 16:09:43,
whisper/normalizers/basic.py,6e3be77,Jong Wook Kim,initial commit,1,32,,,0,2022-09-21 16:09:43,
whisper/normalizers/basic.py,6e3be77,Jong Wook Kim,initial commit,65,75,,,0,2022-09-21 16:09:43,
whisper/normalizers/basic.py,6e3be77,Jong Wook Kim,initial commit,57,61,,,0,2022-09-21 16:09:43,
whisper/normalizers/basic.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",55,56,Jong Wook Kim,6e3be77,1,2023-03-06 23:50:37,2022-09-21 16:09:43
whisper/normalizers/basic.py,26a7cac,Christian Clauss,"pre-commit autoupdate && pre-commit run --all-files (#2484)  * pre-commit autoupdate && pre-commit run --all-files  * Black formatter needs a current version of Python",33,45,Jong Wook Kim,b80bcf6,0,2025-01-04 09:02:18,2023-03-06 23:50:37
whisper/normalizers/basic.py,6e3be77,Jong Wook Kim,initial commit,46,54,,,0,2022-09-21 16:09:43,
whisper/normalizers/basic.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",76,78,Jong Wook Kim,6e3be77,1,2023-03-06 23:50:37,2022-09-21 16:09:43
whisper/normalizers/basic.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",62,64,Jong Wook Kim,6e3be77,1,2023-03-06 23:50:37,2022-09-21 16:09:43
whisper/normalizers/basic.py,6e3be77,Jong Wook Kim,initial commit,79,80,,,0,2022-09-21 16:09:43,
tests/jfk.flac,6e3be77,Jong Wook Kim,initial commit,1,5156,,,0,2022-09-21 16:09:43,
whisper/normalizers/__init__.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",1,2,Jong Wook Kim,6e3be77,1,2023-03-06 23:50:37,2022-09-21 16:09:43
whisper/normalizers/english.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",112,115,Jong Wook Kim,6e3be77,1,2023-03-06 23:50:37,2022-09-21 16:09:43
whisper/normalizers/english.py,6e3be77,Jong Wook Kim,initial commit,89,111,,,0,2022-09-21 16:09:43,
whisper/normalizers/english.py,6e3be77,Jong Wook Kim,initial commit,116,134,,,0,2022-09-21 16:09:43,
whisper/normalizers/english.py,6e3be77,Jong Wook Kim,initial commit,137,225,,,0,2022-09-21 16:09:43,
whisper/normalizers/english.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",226,228,Jong Wook Kim,6e3be77,1,2023-03-06 23:50:37,2022-09-21 16:09:43
whisper/normalizers/english.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",87,88,Jong Wook Kim,6e3be77,1,2023-03-06 23:50:37,2022-09-21 16:09:43
whisper/normalizers/english.py,6e3be77,Jong Wook Kim,initial commit,1,86,,,0,2022-09-21 16:09:43,
whisper/normalizers/english.py,6e3be77,Jong Wook Kim,initial commit,229,531,,,0,2022-09-21 16:09:43,
whisper/normalizers/english.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",532,532,Jong Wook Kim,6e3be77,1,2023-03-06 23:50:37,2022-09-21 16:09:43
whisper/normalizers/english.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",135,136,Jong Wook Kim,6e3be77,1,2023-03-06 23:50:37,2022-09-21 16:09:43
whisper/normalizers/english.py,6e3be77,Jong Wook Kim,initial commit,533,538,,,0,2022-09-21 16:09:43,
whisper/normalizers/english.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",539,539,Jong Wook Kim,6e3be77,1,2023-03-06 23:50:37,2022-09-21 16:09:43
whisper/normalizers/english.py,6e3be77,Jong Wook Kim,initial commit,549,550,,,0,2022-09-21 16:09:43,
whisper/normalizers/english.py,6e3be77,Jong Wook Kim,initial commit,540,547,,,0,2022-09-21 16:09:43,
whisper/normalizers/english.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",548,548,Jong Wook Kim,6e3be77,1,2023-03-06 23:50:37,2022-09-21 16:09:43
whisper/audio.py,6e3be77,Jong Wook Kim,initial commit,1,2,,,0,2022-09-21 16:09:43,
whisper/audio.py,6e3be77,Jong Wook Kim,initial commit,6,14,,,0,2022-09-21 16:09:43,
whisper/audio.py,6e3be77,Jong Wook Kim,initial commit,15,16,,,0,2022-09-21 16:09:43,
whisper/audio.py,6e3be77,Jong Wook Kim,initial commit,5,5,,,0,2022-09-21 16:09:43,
whisper/audio.py,6e3be77,Jong Wook Kim,initial commit,19,19,,,0,2022-09-21 16:09:43,
whisper/audio.py,919a713,Jong Wook Kim,"attempt to fix the repetition/hallucination issue identified in #1046 (#1052)  * attempt to fix the repetition/hallucination issue identified in #1046  * zero-pad the audio instead of spectrogram  * formatting fix  * delete debug print",4,4,Jong Wook Kim,b80bcf6,1,2023-03-08 04:08:45,2023-03-06 23:50:37
whisper/audio.py,8035e9e,petterreinholdtsen,"Drop ffmpeg-python dependency and call ffmpeg directly. (#1242)  * Drop ffmpeg-python dependency and call ffmpeg directly.  The last ffmpeg-python module release was in 2019[1], upstream seem to be unavailable[2] and the project development seem to have stagnated[3].  As the features it provide is trivial to replace using the Python native subprocess module, drop the dependency.   [1] <URL: https://github.com/kkroening/ffmpeg-python/tags >  [2] <URL: https://github.com/kkroening/ffmpeg-python/issues/760 >  [3] <URL: https://openhub.net/p/ffmpeg-python >  * Rewrote to use subprocess.run() instead of subprocess.Popen().  * formatting changes  * formatting update  * isort fix  * Error checking  * isort 🤦🏻  * flake8 fix  * minor spelling changes  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",3,3,Jong Wook Kim,919a713,1,2023-05-04 17:53:59,2023-03-08 04:08:45
whisper/audio.py,919a713,Jong Wook Kim,"attempt to fix the repetition/hallucination issue identified in #1046 (#1052)  * attempt to fix the repetition/hallucination issue identified in #1046  * zero-pad the audio instead of spectrogram  * formatting fix  * delete debug print",17,18,Jong Wook Kim,b80bcf6,1,2023-03-08 04:08:45,2023-03-06 23:50:37
whisper/audio.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",20,20,Markus Hennerbichler,6df3ea1,1,2023-03-06 22:00:49,2023-01-17 07:46:15
whisper/audio.py,6e3be77,Jong Wook Kim,initial commit,24,40,,,0,2022-09-21 16:09:43,
whisper/audio.py,6e3be77,Jong Wook Kim,initial commit,57,57,,,0,2022-09-21 16:09:43,
whisper/audio.py,59f543e,Ram Rachum,Fix exception cause in audio.py (#33),60,60,,,1,2022-09-23 03:12:37,
whisper/audio.py,8035e9e,petterreinholdtsen,"Drop ffmpeg-python dependency and call ffmpeg directly. (#1242)  * Drop ffmpeg-python dependency and call ffmpeg directly.  The last ffmpeg-python module release was in 2019[1], upstream seem to be unavailable[2] and the project development seem to have stagnated[3].  As the features it provide is trivial to replace using the Python native subprocess module, drop the dependency.   [1] <URL: https://github.com/kkroening/ffmpeg-python/tags >  [2] <URL: https://github.com/kkroening/ffmpeg-python/issues/760 >  [3] <URL: https://openhub.net/p/ffmpeg-python >  * Rewrote to use subprocess.run() instead of subprocess.Popen().  * formatting changes  * formatting update  * isort fix  * Error checking  * isort 🤦🏻  * flake8 fix  * minor spelling changes  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",58,59,Jong Wook Kim,919a713,1,2023-05-04 17:53:59,2023-03-08 04:08:45
whisper/audio.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",23,23,Markus Hennerbichler,6df3ea1,1,2023-03-06 22:00:49,2023-01-17 07:46:15
whisper/audio.py,8035e9e,petterreinholdtsen,"Drop ffmpeg-python dependency and call ffmpeg directly. (#1242)  * Drop ffmpeg-python dependency and call ffmpeg directly.  The last ffmpeg-python module release was in 2019[1], upstream seem to be unavailable[2] and the project development seem to have stagnated[3].  As the features it provide is trivial to replace using the Python native subprocess module, drop the dependency.   [1] <URL: https://github.com/kkroening/ffmpeg-python/tags >  [2] <URL: https://github.com/kkroening/ffmpeg-python/issues/760 >  [3] <URL: https://openhub.net/p/ffmpeg-python >  * Rewrote to use subprocess.run() instead of subprocess.Popen().  * formatting changes  * formatting update  * isort fix  * Error checking  * isort 🤦🏻  * flake8 fix  * minor spelling changes  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",41,56,Jong Wook Kim,919a713,1,2023-05-04 17:53:59,2023-03-08 04:08:45
whisper/audio.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",21,22,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/audio.py,6e3be77,Jong Wook Kim,initial commit,61,70,,,0,2022-09-21 16:09:43,
whisper/audio.py,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",100,100,Mohamad Zamini,7dfcd56,1,2023-11-06 18:10:30,2023-11-06 10:28:51
whisper/audio.py,6e3be77,Jong Wook Kim,initial commit,93,99,,,0,2022-09-21 16:09:43,
whisper/audio.py,6e3be77,Jong Wook Kim,initial commit,101,102,,,0,2022-09-21 16:09:43,
whisper/audio.py,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",103,103,Mohamad Zamini,7dfcd56,1,2023-11-06 18:10:30,2023-11-06 10:28:51
whisper/audio.py,7dfcd56,Mohamad Zamini,"allow_pickle=False while loading of mel matrix IN audio.py (#1511)  * Update audio.py   The `mel_filters` function is using a `np.load` function to load a pre-computed mel filterbank matrix. This function is not thread-safe, which means that if it is called from multiple threads at the same time, it may corrupt the data.  To fix this, you can use the `torch.load` function instead. This function is thread-safe, so it will not corrupt the data if it is called from multiple threads at the same time.  * Update audio.py  updated the docstring  * allow_pickle=False  * newline  ---------  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu> Co-authored-by: Jong Wook Kim <jongwook@openai.com>",104,106,petterreinholdtsen,8035e9e,1,2023-11-06 10:28:51,2023-05-04 17:53:59
whisper/audio.py,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",92,92,Mohamad Zamini,7dfcd56,1,2023-11-06 18:10:30,2023-11-06 10:28:51
whisper/audio.py,6e3be77,Jong Wook Kim,initial commit,74,91,,,0,2022-09-21 16:09:43,
whisper/audio.py,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",112,112,Mohamad Zamini,7dfcd56,1,2023-11-06 18:10:30,2023-11-06 10:28:51
whisper/audio.py,919a713,Jong Wook Kim,"attempt to fix the repetition/hallucination issue identified in #1046 (#1052)  * attempt to fix the repetition/hallucination issue identified in #1046  * zero-pad the audio instead of spectrogram  * formatting fix  * delete debug print",113,114,Jong Wook Kim,b80bcf6,1,2023-03-08 04:08:45,2023-03-06 23:50:37
whisper/audio.py,6e3be77,Jong Wook Kim,initial commit,116,124,,,0,2022-09-21 16:09:43,
whisper/audio.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",71,73,,,1,2023-03-06 23:50:37,
whisper/audio.py,6e3be77,Jong Wook Kim,initial commit,107,109,,,0,2022-09-21 16:09:43,
whisper/audio.py,6e3be77,Jong Wook Kim,initial commit,126,126,,,0,2022-09-21 16:09:43,
whisper/audio.py,fc5ded7,Lowell Vaughn,Updating README and doc strings to reflect that n_mels can now be 128 (#2049),125,125,Jong Wook Kim,c5d4256,0,2024-11-26 17:37:01,2023-11-06 18:10:30
whisper/audio.py,919a713,Jong Wook Kim,"attempt to fix the repetition/hallucination issue identified in #1046 (#1052)  * attempt to fix the repetition/hallucination issue identified in #1046  * zero-pad the audio instead of spectrogram  * formatting fix  * delete debug print",127,132,Jong Wook Kim,b80bcf6,1,2023-03-08 04:08:45,2023-03-06 23:50:37
whisper/audio.py,6e3be77,Jong Wook Kim,initial commit,133,134,,,0,2022-09-21 16:09:43,
whisper/audio.py,919a713,Jong Wook Kim,"attempt to fix the repetition/hallucination issue identified in #1046 (#1052)  * attempt to fix the repetition/hallucination issue identified in #1046  * zero-pad the audio instead of spectrogram  * formatting fix  * delete debug print",111,111,,,1,2023-03-08 04:08:45,
whisper/audio.py,6e3be77,Jong Wook Kim,initial commit,136,142,,,0,2022-09-21 16:09:43,
whisper/audio.py,6e3be77,Jong Wook Kim,initial commit,147,148,,,0,2022-09-21 16:09:43,
whisper/audio.py,fc5ded7,Lowell Vaughn,Updating README and doc strings to reflect that n_mels can now be 128 (#2049),135,135,Jong Wook Kim,c5d4256,0,2024-11-26 17:37:01,2023-11-06 18:10:30
whisper/audio.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",115,115,,,1,2023-03-06 23:50:37,
whisper/audio.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",110,110,,,1,2023-03-06 23:50:37,
whisper/audio.py,6e3be77,Jong Wook Kim,initial commit,150,157,,,0,2022-09-21 16:09:43,
whisper/audio.py,6df3ea1,Markus Hennerbichler,Support batch-dimension in log_mel_spectogram (#839),149,149,,,0,2023-01-17 07:46:15,
whisper/audio.py,919a713,Jong Wook Kim,"attempt to fix the repetition/hallucination issue identified in #1046 (#1052)  * attempt to fix the repetition/hallucination issue identified in #1046  * zero-pad the audio instead of spectrogram  * formatting fix  * delete debug print",143,146,,,1,2023-03-08 04:08:45,
whisper/triton_ops.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",46,48,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/triton_ops.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",5,13,,,1,2023-03-06 22:00:49,
whisper/triton_ops.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",14,16,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/triton_ops.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",1,1,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/triton_ops.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",2,4,,,1,2023-03-06 22:00:49,
whisper/triton_ops.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",49,52,,,1,2023-03-06 22:00:49,
whisper/triton_ops.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",53,53,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/triton_ops.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",17,45,,,1,2023-03-06 22:00:49,
whisper/triton_ops.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",57,57,,,1,2023-03-06 22:00:49,
whisper/triton_ops.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",60,60,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/triton_ops.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",61,62,,,1,2023-03-06 22:00:49,
whisper/triton_ops.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",54,55,,,1,2023-03-06 22:00:49,
whisper/triton_ops.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",59,59,,,1,2023-03-06 22:00:49,
whisper/triton_ops.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",63,92,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/triton_ops.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",58,58,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/triton_ops.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",56,56,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/triton_ops.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",93,109,,,1,2023-03-06 22:00:49,
whisper/timing.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",5,5,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/timing.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",30,32,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/timing.py,671ac5a,Guillaume Klein,"Fix alignment between the segments and the list of words (#1087)  * Fix alignment between the segments and the list of words  * Ensure the word index does not overflow",1,1,Jong Wook Kim,38f2f4d,1,2023-03-13 23:34:09,2023-03-08 23:34:07
whisper/timing.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",6,29,,,1,2023-03-06 22:00:49,
whisper/timing.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",33,38,,,1,2023-03-06 22:00:49,
whisper/timing.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",2,4,,,1,2023-03-06 22:00:49,
whisper/timing.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",40,55,,,1,2023-03-06 22:00:49,
whisper/timing.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",39,39,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/timing.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",132,132,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/timing.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",117,131,,,1,2023-03-06 22:00:49,
whisper/timing.py,7ca9fbe,Paul Willot,"Fix numba depreceation notice (#1233)  From numba 0.57 raise a warning if `nopython` is not supplied: https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit",57,57,ryanheise,255887f,1,2023-05-05 06:48:06,2023-04-11 00:23:53
whisper/timing.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",114,116,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/timing.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",58,113,,,1,2023-03-06 22:00:49,
whisper/timing.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",133,134,,,1,2023-03-06 22:00:49,
whisper/timing.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",56,56,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/timing.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",135,137,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/timing.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",138,172,,,1,2023-03-06 22:00:49,
whisper/timing.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",176,193,,,1,2023-03-06 22:00:49,
whisper/timing.py,79c43e4,Jong Wook Kim,abort find_alignment on empty input (#1090),173,175,Guillaume Klein,671ac5a,0,2023-03-14 19:47:58,2023-03-13 23:34:09
whisper/timing.py,27f9713,Jong Wook Kim,"using sdpa if available (#2359)  * using sdpa if available  * Update model.py",194,196,ryanheise,ba3f3cd,0,2024-09-30 17:27:14,2023-12-18 20:11:16
whisper/timing.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",197,197,,,1,2023-03-06 22:00:49,
whisper/timing.py,8b330df,Arthur Kim,"Add .pre-commit-config.yaml (#1528)  * Add .pre-commit-config.yaml  Co-authored-by: arthur <arthur@rtzr.ai>  * flake8 E741  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",207,207,taylorchu,e8622f9,0,2023-09-18 23:15:33,2023-08-07 21:48:56
whisper/timing.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",202,206,,,1,2023-03-06 22:00:49,
whisper/timing.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",198,201,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/timing.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",208,214,,,1,2023-03-06 22:00:49,
whisper/timing.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",215,215,,,1,2023-03-06 23:50:37,
whisper/timing.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",216,218,,,1,2023-03-06 22:00:49,
whisper/timing.py,e8622f9,taylorchu,"word timing tweaks (#1559)  * word timing tweaks  * comment on eot  * clearer comments",219,225,ryanheise,f572f21,0,2023-08-07 21:48:56,2023-06-29 23:51:24
whisper/timing.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",226,232,,,1,2023-03-06 22:00:49,
whisper/timing.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",235,236,,,1,2023-03-06 22:00:49,
whisper/timing.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",233,234,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/timing.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",286,287,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/timing.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",289,289,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/timing.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",237,285,,,1,2023-03-06 22:00:49,
whisper/timing.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",290,293,,,1,2023-03-06 22:00:49,
whisper/timing.py,f572f21,ryanheise,"Improve timestamp heuristics. (#1461)  * Improve timestamp heuristics.  * Track pauses with last_speech_timestamp",301,303,Paul Willot,7ca9fbe,0,2023-06-29 23:51:24,2023-05-05 06:48:06
whisper/timing.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",300,300,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/timing.py,f572f21,ryanheise,"Improve timestamp heuristics. (#1461)  * Improve timestamp heuristics.  * Track pauses with last_speech_timestamp",288,288,Jong Wook Kim,38f2f4d,0,2023-06-29 23:51:24,2023-03-08 23:34:07
whisper/timing.py,f572f21,ryanheise,"Improve timestamp heuristics. (#1461)  * Improve timestamp heuristics.  * Track pauses with last_speech_timestamp",310,318,Paul Willot,7ca9fbe,0,2023-06-29 23:51:24,2023-05-05 06:48:06
whisper/timing.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",319,321,,,1,2023-03-06 22:00:49,
whisper/timing.py,671ac5a,Guillaume Klein,"Fix alignment between the segments and the list of words (#1087)  * Fix alignment between the segments and the list of words  * Ensure the word index does not overflow",294,299,Jong Wook Kim,38f2f4d,1,2023-03-13 23:34:09,2023-03-08 23:34:07
whisper/timing.py,ba3f3cd,ryanheise,"Skip silence around hallucinations (#1838)  * Add clip_timestamps option  * Add hallucination_silence_threshold option  * Fix typing for python < 3.9  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",304,304,Arthur Kim,8b330df,1,2023-12-18 20:11:16,2023-09-18 23:15:33
whisper/timing.py,f572f21,ryanheise,"Improve timestamp heuristics. (#1461)  * Improve timestamp heuristics.  * Track pauses with last_speech_timestamp",305,309,Paul Willot,7ca9fbe,0,2023-06-29 23:51:24,2023-05-05 06:48:06
whisper/timing.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",339,339,,,1,2023-03-06 23:50:37,
whisper/timing.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",340,340,,,1,2023-03-06 22:00:49,
whisper/timing.py,671ac5a,Guillaume Klein,"Fix alignment between the segments and the list of words (#1087)  * Fix alignment between the segments and the list of words  * Ensure the word index does not overflow",322,338,Jong Wook Kim,38f2f4d,1,2023-03-13 23:34:09,2023-03-08 23:34:07
whisper/timing.py,f572f21,ryanheise,"Improve timestamp heuristics. (#1461)  * Improve timestamp heuristics.  * Track pauses with last_speech_timestamp",344,345,Paul Willot,7ca9fbe,0,2023-06-29 23:51:24,2023-05-05 06:48:06
whisper/timing.py,f572f21,ryanheise,"Improve timestamp heuristics. (#1461)  * Improve timestamp heuristics.  * Track pauses with last_speech_timestamp",347,375,Paul Willot,7ca9fbe,0,2023-06-29 23:51:24,2023-05-05 06:48:06
whisper/timing.py,f572f21,ryanheise,"Improve timestamp heuristics. (#1461)  * Improve timestamp heuristics.  * Track pauses with last_speech_timestamp",380,382,Paul Willot,7ca9fbe,0,2023-06-29 23:51:24,2023-05-05 06:48:06
whisper/timing.py,671ac5a,Guillaume Klein,"Fix alignment between the segments and the list of words (#1087)  * Fix alignment between the segments and the list of words  * Ensure the word index does not overflow",346,346,,,1,2023-03-13 23:34:09,
whisper/timing.py,255887f,ryanheise,"Squash long words at window and sentence boundaries. (#1114)  * Squash long words at window and sentence boundaries.  * Formatting requirements.  * Fix squashing logic to point to correct words.  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",383,383,,,1,2023-04-11 00:23:53,
whisper/timing.py,671ac5a,Guillaume Klein,"Fix alignment between the segments and the list of words (#1087)  * Fix alignment between the segments and the list of words  * Ensure the word index does not overflow",385,385,,,1,2023-03-13 23:34:09,
whisper/timing.py,671ac5a,Guillaume Klein,"Fix alignment between the segments and the list of words (#1087)  * Fix alignment between the segments and the list of words  * Ensure the word index does not overflow",388,388,,,1,2023-03-13 23:34:09,
whisper/timing.py,255887f,ryanheise,"Squash long words at window and sentence boundaries. (#1114)  * Squash long words at window and sentence boundaries.  * Formatting requirements.  * Fix squashing logic to point to correct words.  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",384,384,,,1,2023-04-11 00:23:53,
whisper/timing.py,671ac5a,Guillaume Klein,"Fix alignment between the segments and the list of words (#1087)  * Fix alignment between the segments and the list of words  * Ensure the word index does not overflow",341,343,,,1,2023-03-13 23:34:09,
whisper/timing.py,255887f,ryanheise,"Squash long words at window and sentence boundaries. (#1114)  * Squash long words at window and sentence boundaries.  * Formatting requirements.  * Fix squashing logic to point to correct words.  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",376,379,,,1,2023-04-11 00:23:53,
whisper/timing.py,f572f21,ryanheise,"Improve timestamp heuristics. (#1461)  * Improve timestamp heuristics.  * Track pauses with last_speech_timestamp",386,387,,,0,2023-06-29 23:51:24,
whisper/version.py,25639fc,Jong Wook Kim,Release 20240930,1,1,Jong Wook Kim,423492d,0,2024-09-30 18:20:53,2024-09-27 23:43:58
whisper/__init__.py,6e3be77,Jong Wook Kim,initial commit,1,12,,,0,2022-09-21 16:09:43,
whisper/__init__.py,6e3be77,Jong Wook Kim,initial commit,14,14,,,0,2022-09-21 16:09:43,
whisper/__init__.py,6e3be77,Jong Wook Kim,initial commit,16,16,,,0,2022-09-21 16:09:43,
whisper/__init__.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",13,13,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/__init__.py,b9f9b43,Romain Beaumont,"Add github action to automatically push to pypi on Release x.y.z commit (#681)  * Add github action to automatically push to pypi on Release x.y.z commit  * some housekeeping for pypi upload  * add version.py  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",15,15,Paul Harter,fd8f80c,0,2023-01-17 23:50:26,2022-12-06 17:07:19
whisper/__init__.py,4179ed2,Jong Wook Kim,"add large-v2 model  - The ""large-v2"" model is trained for more epochs with regularization and shows improved performance compared to the previous large. - It has the same architecture as the original large model. - When `load_model(""large"")` is called, the ""large-v2"" model will be loaded. - We will soon update the paper regarding this new model.",26,27,David Marx,82725ce,0,2022-12-05 16:07:14,2022-10-09 09:14:03
whisper/__init__.py,25e5c36,Jong Wook Kim,large-v3-turbo model (#2361),30,31,Jong Wook Kim,c5d4256,0,2024-09-30 17:59:51,2023-11-06 18:10:30
whisper/__init__.py,6e3be77,Jong Wook Kim,initial commit,17,25,,,0,2022-09-21 16:09:43,
whisper/__init__.py,6e3be77,Jong Wook Kim,initial commit,32,33,,,0,2022-09-21 16:09:43,
whisper/__init__.py,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",28,29,Jong Wook Kim,b80bcf6,1,2023-11-06 18:10:30,2023-03-06 23:50:37
whisper/__init__.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",34,45,zer0-x,9f7aba6,1,2023-03-06 22:00:49,2023-01-21 09:09:39
whisper/__init__.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",46,46,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/__init__.py,f296bcd,Niklas K,"Avoid keeping redundant copies of model weights in memory during load (#42)  * don't keep copies of model weights in host memory  * adding type annotation  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",54,54,,,0,2022-09-23 03:57:39,
whisper/__init__.py,6e3be77,Jong Wook Kim,initial commit,56,57,,,0,2022-09-21 16:09:43,
whisper/__init__.py,25e5c36,Jong Wook Kim,large-v3-turbo model (#2361),49,50,Jong Wook Kim,c5d4256,0,2024-09-30 17:59:51,2023-11-06 18:10:30
whisper/__init__.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",51,53,zer0-x,9f7aba6,1,2023-03-06 22:00:49,2023-01-21 09:09:39
whisper/__init__.py,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",47,48,Jong Wook Kim,b80bcf6,1,2023-11-06 18:10:30,2023-03-06 23:50:37
whisper/__init__.py,6e3be77,Jong Wook Kim,initial commit,55,55,,,0,2022-09-21 16:09:43,
whisper/__init__.py,6e3be77,Jong Wook Kim,initial commit,66,66,,,0,2022-09-21 16:09:43,
whisper/__init__.py,6e3be77,Jong Wook Kim,initial commit,59,63,,,0,2022-09-21 16:09:43,
whisper/__init__.py,f296bcd,Niklas K,"Avoid keeping redundant copies of model weights in memory during load (#42)  * don't keep copies of model weights in host memory  * adding type annotation  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",58,58,Jong Wook Kim,6e3be77,0,2022-09-23 03:57:39,2022-09-21 16:09:43
whisper/__init__.py,f296bcd,Niklas K,"Avoid keeping redundant copies of model weights in memory during load (#42)  * don't keep copies of model weights in host memory  * adding type annotation  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",67,67,Jong Wook Kim,6e3be77,0,2022-09-23 03:57:39,2022-09-21 16:09:43
whisper/__init__.py,6e3be77,Jong Wook Kim,initial commit,68,68,,,0,2022-09-21 16:09:43,
whisper/__init__.py,fd8f80c,Paul Harter,Explicitly closing model file after reading it (#630),64,65,Jong Wook Kim,6e3be77,0,2022-12-06 17:07:19,2022-09-21 16:09:43
whisper/__init__.py,6e3be77,Jong Wook Kim,initial commit,81,90,,,0,2022-09-21 16:09:43,
whisper/__init__.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",69,71,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/__init__.py,6e3be77,Jong Wook Kim,initial commit,72,73,,,0,2022-09-21 16:09:43,
whisper/__init__.py,6e3be77,Jong Wook Kim,initial commit,94,94,,,0,2022-09-21 16:09:43,
whisper/__init__.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",74,80,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/__init__.py,6e3be77,Jong Wook Kim,initial commit,109,120,,,0,2022-09-21 16:09:43,
whisper/__init__.py,6e3be77,Jong Wook Kim,initial commit,96,102,,,0,2022-09-21 16:09:43,
whisper/__init__.py,f296bcd,Niklas K,"Avoid keeping redundant copies of model weights in memory during load (#42)  * don't keep copies of model weights in host memory  * adding type annotation  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",95,95,Jong Wook Kim,6e3be77,0,2022-09-23 03:57:39,2022-09-21 16:09:43
whisper/__init__.py,6e3be77,Jong Wook Kim,initial commit,123,128,,,0,2022-09-21 16:09:43,
whisper/__init__.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",103,108,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/__init__.py,f296bcd,Niklas K,"Avoid keeping redundant copies of model weights in memory during load (#42)  * don't keep copies of model weights in host memory  * adding type annotation  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",121,122,,,0,2022-09-23 03:57:39,
whisper/__init__.py,f296bcd,Niklas K,"Avoid keeping redundant copies of model weights in memory during load (#42)  * don't keep copies of model weights in host memory  * adding type annotation  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",129,132,,,0,2022-09-23 03:57:39,
whisper/__init__.py,f296bcd,Niklas K,"Avoid keeping redundant copies of model weights in memory during load (#42)  * don't keep copies of model weights in host memory  * adding type annotation  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",135,135,,,0,2022-09-23 03:57:39,
whisper/__init__.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",133,134,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/__init__.py,f296bcd,Niklas K,"Avoid keeping redundant copies of model weights in memory during load (#42)  * don't keep copies of model weights in host memory  * adding type annotation  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",137,137,,,0,2022-09-23 03:57:39,
whisper/__init__.py,6e3be77,Jong Wook Kim,initial commit,136,136,,,0,2022-09-21 16:09:43,
whisper/__init__.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",138,138,zer0-x,9f7aba6,1,2023-03-06 22:00:49,2023-01-21 09:09:39
whisper/__init__.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",91,93,Jong Wook Kim,6e3be77,1,2023-03-06 23:50:37,2022-09-21 16:09:43
whisper/__init__.py,f296bcd,Niklas K,"Avoid keeping redundant copies of model weights in memory during load (#42)  * don't keep copies of model weights in host memory  * adding type annotation  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",140,140,,,0,2022-09-23 03:57:39,
whisper/__init__.py,6e3be77,Jong Wook Kim,initial commit,139,139,,,0,2022-09-21 16:09:43,
whisper/__init__.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",141,141,zer0-x,9f7aba6,1,2023-03-06 22:00:49,2023-01-21 09:09:39
whisper/__init__.py,6e3be77,Jong Wook Kim,initial commit,146,146,,,0,2022-09-21 16:09:43,
whisper/__init__.py,6e3be77,Jong Wook Kim,initial commit,142,142,,,0,2022-09-21 16:09:43,
whisper/__init__.py,f296bcd,Niklas K,"Avoid keeping redundant copies of model weights in memory during load (#42)  * don't keep copies of model weights in host memory  * adding type annotation  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",150,151,,,0,2022-09-23 03:57:39,
whisper/__init__.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",143,145,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/__init__.py,6e3be77,Jong Wook Kim,initial commit,152,153,,,0,2022-09-21 16:09:43,
whisper/__init__.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",147,149,zer0-x,9f7aba6,1,2023-03-06 23:50:37,2023-01-21 09:09:39
whisper/__init__.py,6e3be77,Jong Wook Kim,initial commit,154,154,,,0,2022-09-21 16:09:43,
whisper/__init__.py,f296bcd,Niklas K,"Avoid keeping redundant copies of model weights in memory during load (#42)  * don't keep copies of model weights in host memory  * adding type annotation  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",155,155,,,0,2022-09-23 03:57:39,
whisper/__init__.py,6e3be77,Jong Wook Kim,initial commit,156,156,,,0,2022-09-21 16:09:43,
whisper/__init__.py,6e3be77,Jong Wook Kim,initial commit,160,160,,,0,2022-09-21 16:09:43,
whisper/__init__.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",157,159,,,1,2023-03-06 22:00:49,
whisper/__main__.py,6e3be77,Jong Wook Kim,initial commit,3,3,,,0,2022-09-21 16:09:43,
whisper/__main__.py,6e3be77,Jong Wook Kim,initial commit,1,2,,,0,2022-09-21 16:09:43,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,1,3,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,14,23,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",4,4,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,10,12,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,5,8,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",9,9,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",13,13,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",24,26,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,27,32,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",33,36,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,40,42,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,37,39,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,46,48,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,55,58,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",43,45,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,60,125,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",54,54,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,50,53,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",59,59,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",49,49,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,129,131,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",126,128,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",132,132,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",144,146,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",137,137,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,147,149,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,138,143,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",150,150,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,133,136,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,151,154,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",155,155,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,156,199,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,203,205,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",200,202,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,212,218,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",206,206,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",219,221,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,207,210,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,222,224,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",211,211,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",225,225,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,226,229,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,231,258,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",230,230,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",260,260,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,259,259,Jong Wook Kim,49a3ffc,0,2022-12-09 05:12:39,2022-09-21 20:36:25
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,266,269,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,264,264,,,0,2022-09-21 20:36:25,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,261,263,Jong Wook Kim,49a3ffc,0,2022-12-09 05:12:39,2022-09-21 20:36:25
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",265,265,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,270,270,Jong Wook Kim,49a3ffc,0,2022-12-09 05:12:39,2022-09-21 20:36:25
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,273,276,,,0,2022-09-21 20:36:25,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,277,277,Jong Wook Kim,49a3ffc,0,2022-12-09 05:12:39,2022-09-21 20:36:25
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,280,283,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",272,272,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,271,271,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",279,279,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,278,278,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,285,285,,,0,2022-09-21 20:36:25,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,284,284,Jong Wook Kim,49a3ffc,0,2022-12-09 05:12:39,2022-09-21 20:36:25
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",286,286,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,294,297,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,292,292,,,0,2022-09-21 20:36:25,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,291,291,Jong Wook Kim,49a3ffc,0,2022-12-09 05:12:39,2022-09-21 20:36:25
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,287,290,,,0,2022-09-21 20:36:25,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,298,298,Jong Wook Kim,49a3ffc,0,2022-12-09 05:12:39,2022-09-21 20:36:25
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,299,299,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",293,293,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,305,305,Jong Wook Kim,49a3ffc,0,2022-12-09 05:12:39,2022-09-21 20:36:25
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,301,304,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",307,307,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",300,300,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,308,311,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,306,306,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,313,313,,,0,2022-09-21 20:36:25,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,312,312,Jong Wook Kim,49a3ffc,0,2022-12-09 05:12:39,2022-09-21 20:36:25
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",314,314,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,315,318,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",333,334,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,332,332,Jong Wook Kim,49a3ffc,0,2022-12-09 05:12:39,2022-09-21 20:36:25
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,329,331,,,0,2022-09-21 20:36:25,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,319,319,Jong Wook Kim,49a3ffc,0,2022-12-09 05:12:39,2022-09-21 20:36:25
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,320,320,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",321,328,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",396,501,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,335,395,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",618,623,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,617,617,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",575,616,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,502,574,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,624,627,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",628,628,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,629,649,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",650,699,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,700,701,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",702,703,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",705,708,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",720,721,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,704,704,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,722,722,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",711,717,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,709,710,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,718,719,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",723,723,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,727,727,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",820,820,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,821,829,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,729,819,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,724,725,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",728,728,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",726,726,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",830,831,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,832,838,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",839,882,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,883,893,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,896,896,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",900,902,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,903,903,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,898,899,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",897,897,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",894,895,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,916,917,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",904,915,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",918,942,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,943,944,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,960,960,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",945,959,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,1052,1054,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",961,1051,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1055,1060,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,1061,1064,,,0,2022-09-21 20:36:25,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,1070,1070,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1067,1067,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,1066,1066,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1074,1075,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1065,1065,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,1073,1073,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1071,1072,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,1068,1069,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,1076,1080,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,1096,1099,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,1101,1101,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1089,1095,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,1088,1088,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1102,1102,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1100,1100,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1081,1087,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,1103,1104,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,1106,1106,,,0,2022-09-21 20:36:25,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,1105,1105,Jong Wook Kim,49a3ffc,0,2022-12-09 05:12:39,2022-09-21 20:36:25
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1107,1107,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,1201,1201,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,1108,1133,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1134,1158,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1202,1202,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1200,1200,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,1159,1199,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,1203,1204,,,0,2022-09-21 20:36:25,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,1205,1205,,,0,2022-12-09 05:12:39,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,1208,1208,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1206,1207,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,1254,1256,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,1261,1264,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1267,1267,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1209,1253,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1257,1260,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,1268,1269,,,0,2022-12-09 05:12:39,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,1265,1266,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1270,1270,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,1271,1271,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,1287,1288,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,1273,1282,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,1285,1285,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1286,1286,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,1284,1284,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1289,1291,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1272,1272,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1283,1283,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,1300,1302,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1293,1299,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,1292,1292,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1314,1322,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1303,1309,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,1310,1313,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1324,1381,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,1382,1382,,,0,2022-09-21 20:36:25,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,1323,1323,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1383,1383,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,1389,1429,,,0,2022-09-21 20:36:25,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,1386,1386,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1388,1388,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,1430,1430,,,0,2022-12-09 05:12:39,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,1387,1387,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,1384,1385,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1431,1431,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,1432,1432,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1433,1433,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1437,1565,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,1434,1436,,,0,2022-12-09 05:12:39,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,1601,1602,Jong Wook Kim,49a3ffc,0,2022-12-09 05:12:39,2022-09-21 20:36:25
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,1566,1587,Jong Wook Kim,49a3ffc,0,2022-12-09 05:12:39,2022-09-21 20:36:25
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1588,1600,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1610,1611,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,1607,1609,Jong Wook Kim,49a3ffc,0,2022-12-09 05:12:39,2022-09-21 20:36:25
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1603,1606,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,1612,1612,,,0,2022-12-09 05:12:39,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,1614,1615,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1613,1613,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,1751,1759,Jong Wook Kim,49a3ffc,0,2022-12-09 05:12:39,2022-09-21 20:36:25
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1616,1733,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1735,1750,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1760,1761,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,1762,1762,,,0,2022-09-21 20:36:25,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,1734,1734,,,0,2022-12-09 05:12:39,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,1764,1765,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1766,1851,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,1852,1852,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1763,1763,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1891,1892,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,1854,1890,,,0,2022-09-21 20:36:25,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,1893,1893,Jong Wook Kim,49a3ffc,0,2022-12-09 05:12:39,2022-09-21 20:36:25
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1853,1853,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,1912,1914,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1897,1911,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1915,1916,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,1895,1896,,,0,2022-12-09 05:12:39,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,1919,1920,Jong Wook Kim,49a3ffc,0,2022-12-09 05:12:39,2022-09-21 20:36:25
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1894,1894,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,1979,1979,Jong Wook Kim,49a3ffc,0,2022-12-09 05:12:39,2022-09-21 20:36:25
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,1917,1917,Jong Wook Kim,49a3ffc,0,2022-12-09 05:12:39,2022-09-21 20:36:25
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1918,1918,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1921,1978,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",1980,1980,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2014,2014,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2174,2190,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2012,2013,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2191,2193,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2015,2015,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,1981,2011,Jong Wook Kim,49a3ffc,0,2022-12-09 05:12:39,2022-09-21 20:36:25
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2016,2017,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2018,2173,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2194,2201,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2208,2208,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2207,2207,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2202,2204,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2211,2213,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2205,2206,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2209,2210,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2214,2214,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2228,2230,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2250,2250,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2244,2246,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2249,2249,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2215,2227,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2251,2252,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2231,2243,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2247,2248,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2256,2256,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2257,2263,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2253,2255,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2264,2265,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2266,2276,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2277,2283,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2284,2286,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2289,2289,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2287,2288,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2290,2290,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2291,2292,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2293,2304,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2308,2309,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2311,2311,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2305,2307,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2312,2313,,,0,2022-09-21 20:36:25,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,2322,2324,Jong Wook Kim,49a3ffc,0,2022-12-09 05:12:39,2022-09-21 20:36:25
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2310,2310,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2314,2321,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2325,2326,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2328,2328,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2331,2341,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,2327,2327,Jong Wook Kim,49a3ffc,0,2022-12-09 05:12:39,2022-09-21 20:36:25
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,2347,2347,Jong Wook Kim,49a3ffc,0,2022-12-09 05:12:39,2022-09-21 20:36:25
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,2329,2330,Jong Wook Kim,49a3ffc,0,2022-12-09 05:12:39,2022-09-21 20:36:25
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,2342,2344,Jong Wook Kim,49a3ffc,0,2022-12-09 05:12:39,2022-09-21 20:36:25
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2345,2346,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2348,2348,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,2349,2350,Jong Wook Kim,49a3ffc,0,2022-12-09 05:12:39,2022-09-21 20:36:25
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2351,2351,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2363,2364,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,2354,2362,Jong Wook Kim,49a3ffc,0,2022-12-09 05:12:39,2022-09-21 20:36:25
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2353,2353,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2366,2366,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,2352,2352,Jong Wook Kim,49a3ffc,0,2022-12-09 05:12:39,2022-09-21 20:36:25
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,2367,2368,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2369,2375,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,2365,2365,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2385,2393,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2394,2396,,,0,2022-09-21 20:36:25,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,2376,2378,Jong Wook Kim,49a3ffc,0,2022-12-09 05:12:39,2022-09-21 20:36:25
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2382,2382,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2397,2398,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,2381,2381,Jong Wook Kim,49a3ffc,0,2022-12-09 05:12:39,2022-09-21 20:36:25
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2379,2380,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,2383,2384,Jong Wook Kim,49a3ffc,0,2022-12-09 05:12:39,2022-09-21 20:36:25
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2403,2411,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2417,2417,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2399,2399,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2415,2416,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2400,2400,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2418,2418,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2401,2402,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2412,2414,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2419,2420,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2434,2435,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2475,2477,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2431,2433,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2438,2439,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2436,2436,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2437,2437,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2440,2474,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2421,2430,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2482,2483,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2500,2501,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2480,2480,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2497,2499,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2502,2502,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2481,2481,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2484,2496,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2478,2479,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2503,2503,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2504,2505,,,0,2022-09-21 20:36:25,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,2529,2529,,,0,2022-12-09 05:12:39,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,2558,2560,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2543,2557,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2506,2528,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2561,2567,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,2541,2542,Jong Wook Kim,49a3ffc,0,2022-12-09 05:12:39,2022-09-21 20:36:25
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2530,2540,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2568,2570,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2588,2589,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2575,2576,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2590,2590,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2573,2573,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2574,2574,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2577,2584,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2585,2587,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2571,2572,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2591,2591,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2592,2593,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2616,2616,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2639,2647,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2648,2650,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2617,2635,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2636,2638,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2594,2615,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2651,2652,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,2653,2653,Jong Wook Kim,49a3ffc,0,2022-12-09 05:12:39,2022-09-21 20:36:25
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2657,2666,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2670,2671,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2672,2672,,,0,2022-09-21 20:36:25,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,2655,2656,Jong Wook Kim,49a3ffc,0,2022-12-09 05:12:39,2022-09-21 20:36:25
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2673,2673,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2654,2654,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,2667,2669,Jong Wook Kim,49a3ffc,0,2022-12-09 05:12:39,2022-09-21 20:36:25
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2674,2675,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2676,2712,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2722,2746,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2713,2715,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2747,2749,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2720,2721,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2716,2717,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2750,2751,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2718,2718,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2719,2719,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2766,2768,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2771,2771,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2753,2753,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2752,2752,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2769,2770,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2772,2772,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2754,2755,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2756,2765,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2773,2774,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2784,2786,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2791,2792,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2790,2790,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2789,2789,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2803,2805,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2775,2783,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2793,2802,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2787,2788,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2806,2807,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2808,2808,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2812,2824,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2809,2809,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2828,2829,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,2825,2827,Jong Wook Kim,49a3ffc,0,2022-12-09 05:12:39,2022-09-21 20:36:25
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2832,2833,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2830,2830,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2834,2836,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2810,2811,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2831,2831,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2837,2837,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2864,2864,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2838,2849,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2850,2852,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2866,2867,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2862,2863,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2868,2878,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,2853,2861,Jong Wook Kim,49a3ffc,0,2022-12-09 05:12:39,2022-09-21 20:36:25
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2865,2865,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2879,2881,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2891,2900,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2889,2889,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2890,2890,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2882,2883,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2885,2885,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2886,2887,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2884,2884,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2888,2888,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2903,2903,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2908,2914,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2905,2906,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2919,2919,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2915,2918,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2901,2902,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2904,2904,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,2907,2907,Jong Wook Kim,49a3ffc,0,2022-12-09 05:12:39,2022-09-21 20:36:25
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2920,2920,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2935,2937,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,3426,3428,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2921,2921,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2925,2934,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",2938,3425,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,2924,2924,Jong Wook Kim,49a3ffc,0,2022-12-09 05:12:39,2022-09-21 20:36:25
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,2922,2923,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",3429,7441,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,7450,7450,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,7442,7442,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",7443,7449,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",7451,7457,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,7458,7458,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",7466,7890,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,7891,7891,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,7905,7906,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,7465,7465,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",7892,7904,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",7459,7464,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,7908,7909,,,0,2022-09-21 20:36:25,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,7907,7907,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",7910,7920,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",7923,7923,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,7929,7930,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",7926,7928,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,7924,7925,,,0,2022-12-09 05:12:39,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,7932,7933,,,0,2022-09-21 20:36:25,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,7921,7922,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",7931,7931,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,7937,7938,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,7940,7941,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",7934,7936,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",7939,7939,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,7945,7946,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,7948,7949,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",7947,7947,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,7990,7991,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",7942,7944,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",7950,7989,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",7992,7992,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,7993,7994,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",7995,7997,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,7998,7998,,,0,2022-12-09 05:12:39,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8001,8002,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,7999,7999,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8000,8000,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8003,8005,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8006,8006,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8008,8008,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8011,8027,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8007,8007,,,0,2022-09-21 20:36:25,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8028,8028,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8029,8029,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8009,8010,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8031,8031,,,0,2022-09-21 20:36:25,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8030,8030,,,0,2022-12-09 05:12:39,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8032,8032,,,0,2022-12-09 05:12:39,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8033,8034,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8035,8037,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8040,8040,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8043,8045,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8038,8039,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8041,8042,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8047,8047,,,0,2022-09-21 20:36:25,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8046,8046,,,0,2022-12-09 05:12:39,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8049,8050,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8048,8048,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8063,8065,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8055,8062,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8075,8075,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8077,8078,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8076,8076,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8054,8054,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8066,8074,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8051,8053,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8079,8082,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8083,8083,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8084,8084,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8092,8092,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8090,8091,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8093,8094,,,0,2022-09-21 20:36:25,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8085,8086,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8087,8089,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8095,8100,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8101,8102,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8108,8108,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8103,8105,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8106,8107,,,0,2022-12-09 05:12:39,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8115,8115,,,0,2022-12-09 05:12:39,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8114,8114,,,0,2022-09-21 20:36:25,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8109,8110,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8111,8113,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8116,8116,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8122,8123,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8119,8121,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8117,8118,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8124,8124,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8125,8126,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8131,8132,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8136,8138,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8133,8133,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8134,8135,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8127,8129,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8130,8130,,,0,2022-12-09 05:12:39,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8139,8139,,,0,2022-12-09 05:12:39,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8141,8141,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8140,8140,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8142,8142,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8143,8144,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8145,8147,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8150,8150,,,0,2022-09-21 20:36:25,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8148,8148,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8149,8149,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8151,8151,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8152,8153,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8154,8156,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8157,8157,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8158,8158,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8159,8159,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8160,8160,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8163,8165,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8167,8167,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8161,8162,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8170,8171,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8169,8169,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8168,8168,,,0,2022-09-21 20:36:25,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8166,8166,,,0,2022-12-09 05:12:39,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8175,8175,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8172,8174,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8176,8176,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8181,8183,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8186,8186,,,0,2022-09-21 20:36:25,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8184,8184,,,0,2022-12-09 05:12:39,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8179,8180,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8177,8177,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8185,8185,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8178,8178,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8187,8187,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8188,8189,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8194,8195,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8197,8198,,,0,2022-09-21 20:36:25,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8193,8193,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8196,8196,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8190,8192,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8203,8203,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8199,8201,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8202,8202,,,0,2022-12-09 05:12:39,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8204,8204,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8206,8207,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8205,8205,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8214,8214,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8213,8213,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8215,8216,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8212,8212,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8208,8210,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8218,8218,,,0,2022-12-09 05:12:39,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8211,8211,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8217,8217,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8222,8225,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8219,8219,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8226,8228,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8220,8221,,,0,2022-12-09 05:12:39,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8229,8229,,,0,2022-12-09 05:12:39,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8231,8231,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8232,8232,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8230,8230,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8233,8234,,,0,2022-09-21 20:36:25,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8238,8238,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8235,8237,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8240,8240,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8241,8241,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8242,8243,,,0,2022-09-21 20:36:25,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8247,8247,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8239,8239,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8244,8246,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8249,8249,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8248,8248,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8250,8250,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8251,8252,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8259,8259,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8253,8255,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8257,8257,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8258,8258,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8262,8264,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8256,8256,,,0,2022-12-09 05:12:39,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8265,8265,,,0,2022-12-09 05:12:39,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8260,8261,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8266,8266,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8271,8273,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8268,8268,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8269,8270,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8267,8267,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8275,8275,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8277,8277,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8274,8274,,,0,2022-12-09 05:12:39,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8276,8276,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8278,8279,,,0,2022-09-21 20:36:25,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8283,8283,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8284,8284,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8287,8288,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8280,8282,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8285,8285,,,0,2022-09-21 20:36:25,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8292,8292,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8289,8291,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8286,8286,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8296,8297,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8302,8302,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8295,8295,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8301,8301,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8293,8293,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8298,8300,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8303,8303,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8294,8294,,,0,2022-09-21 20:36:25,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8310,8310,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8313,8313,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8304,8304,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8307,8309,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8305,8306,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8312,8312,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8314,8315,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8311,8311,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8316,8318,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8319,8319,,,0,2022-12-09 05:12:39,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8323,8324,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8320,8320,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8322,8322,,,0,2022-12-09 05:12:39,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8321,8321,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8325,8329,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8330,8330,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8334,8338,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8331,8331,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8332,8333,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8343,8345,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8341,8342,,,0,2022-09-21 20:36:25,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8346,8348,,,0,2022-12-09 05:12:39,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8339,8339,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8340,8340,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8352,8352,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8349,8349,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8350,8351,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8359,8360,,,0,2022-09-21 20:36:25,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8353,8353,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8354,8354,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8361,8363,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8355,8358,,,0,2022-12-09 05:12:39,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8368,8369,,,0,2022-09-21 20:36:25,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8364,8364,,,0,2022-12-09 05:12:39,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8366,8366,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8365,8365,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8370,8372,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8367,8367,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8374,8374,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8373,8373,,,0,2022-12-09 05:12:39,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8377,8378,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8376,8376,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8375,8375,,,0,2022-12-09 05:12:39,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8382,8382,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8379,8381,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8385,8385,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8383,8383,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8386,8387,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8392,8392,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8388,8390,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8384,8384,,,0,2022-12-09 05:12:39,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8391,8391,,,0,2022-12-09 05:12:39,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8393,8393,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8397,8401,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8395,8396,,,0,2022-09-21 20:36:25,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8402,8403,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8394,8394,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8413,8414,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8404,8405,,,0,2022-09-21 20:36:25,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8411,8411,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8406,8410,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8415,8419,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8412,8412,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8420,8421,,,0,2022-12-09 05:12:39,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8422,8423,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8424,8426,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8429,8429,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8428,8428,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8427,8427,,,0,2022-12-09 05:12:39,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8430,8430,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8433,8435,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8431,8432,,,0,2022-09-21 20:36:25,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8438,8438,,,0,2022-12-09 05:12:39,
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8436,8436,,,0,2022-12-09 05:12:39,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8440,8441,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8437,8437,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8439,8439,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8442,8446,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,0b5dcfd,Jong Wook Kim,large-v2 figure and arxiv url update,8447,8447,,,0,2022-12-09 05:12:39,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8449,8453,,,0,2022-09-21 20:36:25,
language-breakdown.svg,49a3ffc,Jong Wook Kim,add section Available models and languages,8459,8461,,,0,2022-09-21 20:36:25,
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8448,8448,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
language-breakdown.svg,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",8454,8458,Jong Wook Kim,0b5dcfd,1,2023-11-06 18:10:30,2022-12-09 05:12:39
whisper/model.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",1,2,Jong Wook Kim,5380767,1,2023-03-06 22:00:49,2022-12-30 08:53:57
whisper/model.py,27f9713,Jong Wook Kim,"using sdpa if available (#2359)  * using sdpa if available  * Update model.py",3,3,Jong Wook Kim,c5d4256,0,2024-09-30 17:27:14,2023-11-06 18:10:30
whisper/model.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",10,10,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/model.py,6e3be77,Jong Wook Kim,initial commit,4,4,,,0,2022-09-21 16:09:43,
whisper/model.py,27f9713,Jong Wook Kim,"using sdpa if available (#2359)  * using sdpa if available  * Update model.py",5,5,Jong Wook Kim,c5d4256,0,2024-09-30 17:27:14,2023-11-06 18:10:30
whisper/model.py,6e3be77,Jong Wook Kim,initial commit,11,11,,,0,2022-09-21 16:09:43,
whisper/model.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",12,13,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/model.py,6e3be77,Jong Wook Kim,initial commit,6,9,,,0,2022-09-21 16:09:43,
whisper/model.py,6e3be77,Jong Wook Kim,initial commit,57,70,,,0,2022-09-21 16:09:43,
whisper/model.py,6e3be77,Jong Wook Kim,initial commit,50,53,,,0,2022-09-21 16:09:43,
whisper/model.py,6e3be77,Jong Wook Kim,initial commit,15,15,,,0,2022-09-21 16:09:43,
whisper/model.py,6e3be77,Jong Wook Kim,initial commit,24,46,,,0,2022-09-21 16:09:43,
whisper/model.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",47,49,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/model.py,27f9713,Jong Wook Kim,"using sdpa if available (#2359)  * using sdpa if available  * Update model.py",16,23,Jong Wook Kim,c5d4256,0,2024-09-30 17:27:14,2023-11-06 18:10:30
whisper/model.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",14,14,Jong Wook Kim,5380767,1,2023-03-06 22:00:49,2022-12-30 08:53:57
whisper/model.py,6e3be77,Jong Wook Kim,initial commit,81,81,,,0,2022-09-21 16:09:43,
whisper/model.py,27f9713,Jong Wook Kim,"using sdpa if available (#2359)  * using sdpa if available  * Update model.py",82,83,Jong Wook Kim,c5d4256,0,2024-09-30 17:27:14,2023-11-06 18:10:30
whisper/model.py,27f9713,Jong Wook Kim,"using sdpa if available (#2359)  * using sdpa if available  * Update model.py",71,80,Jong Wook Kim,c5d4256,0,2024-09-30 17:27:14,2023-11-06 18:10:30
whisper/model.py,6e3be77,Jong Wook Kim,initial commit,84,100,,,0,2022-09-21 16:09:43,
whisper/model.py,9f70a35,Vicki Anand,Fix attention caching to make it actually work (#370),108,109,,,1,2022-10-19 23:44:03,
whisper/model.py,6e3be77,Jong Wook Kim,initial commit,102,107,,,0,2022-09-21 16:09:43,
whisper/model.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",54,56,,,1,2023-03-06 23:50:37,
whisper/model.py,9f70a35,Vicki Anand,Fix attention caching to make it actually work (#370),101,101,,,1,2022-10-19 23:44:03,
whisper/model.py,6e3be77,Jong Wook Kim,initial commit,110,110,,,0,2022-09-21 16:09:43,
whisper/model.py,6e3be77,Jong Wook Kim,initial commit,113,113,,,0,2022-09-21 16:09:43,
whisper/model.py,6e3be77,Jong Wook Kim,initial commit,117,118,,,0,2022-09-21 16:09:43,
whisper/model.py,27f9713,Jong Wook Kim,"using sdpa if available (#2359)  * using sdpa if available  * Update model.py",116,116,Jong Wook Kim,c5d4256,0,2024-09-30 17:27:14,2023-11-06 18:10:30
whisper/model.py,27f9713,Jong Wook Kim,"using sdpa if available (#2359)  * using sdpa if available  * Update model.py",123,137,Jong Wook Kim,c5d4256,0,2024-09-30 17:27:14,2023-11-06 18:10:30
whisper/model.py,5380767,Jong Wook Kim,MultiHeadAttention to return qk as well,111,112,,,0,2022-12-30 08:53:57,
whisper/model.py,6e3be77,Jong Wook Kim,initial commit,121,122,,,0,2022-09-21 16:09:43,
whisper/model.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",114,115,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/model.py,27f9713,Jong Wook Kim,"using sdpa if available (#2359)  * using sdpa if available  * Update model.py",119,120,Jong Wook Kim,c5d4256,0,2024-09-30 17:27:14,2023-11-06 18:10:30
whisper/model.py,6e3be77,Jong Wook Kim,initial commit,138,138,,,0,2022-09-21 16:09:43,
whisper/model.py,27f9713,Jong Wook Kim,"using sdpa if available (#2359)  * using sdpa if available  * Update model.py",139,139,Jong Wook Kim,c5d4256,0,2024-09-30 17:27:14,2023-11-06 18:10:30
whisper/model.py,6e3be77,Jong Wook Kim,initial commit,140,148,,,0,2022-09-21 16:09:43,
whisper/model.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",149,151,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/model.py,6e3be77,Jong Wook Kim,initial commit,152,154,,,0,2022-09-21 16:09:43,
whisper/model.py,6e3be77,Jong Wook Kim,initial commit,158,166,,,0,2022-09-21 16:09:43,
whisper/model.py,6e3be77,Jong Wook Kim,initial commit,168,168,,,0,2022-09-21 16:09:43,
whisper/model.py,5380767,Jong Wook Kim,MultiHeadAttention to return qk as well,167,167,,,0,2022-12-30 08:53:57,
whisper/model.py,6e3be77,Jong Wook Kim,initial commit,170,174,,,0,2022-09-21 16:09:43,
whisper/model.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",208,210,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/model.py,6e3be77,Jong Wook Kim,initial commit,178,207,,,0,2022-09-21 16:09:43,
whisper/model.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",217,220,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/model.py,5380767,Jong Wook Kim,MultiHeadAttention to return qk as well,169,169,,,0,2022-12-30 08:53:57,
whisper/model.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",155,157,,,1,2023-03-06 23:50:37,
whisper/model.py,6e3be77,Jong Wook Kim,initial commit,211,216,,,0,2022-09-21 16:09:43,
whisper/model.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",175,177,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/model.py,6e3be77,Jong Wook Kim,initial commit,221,230,,,0,2022-09-21 16:09:43,
whisper/model.py,6e3be77,Jong Wook Kim,initial commit,232,234,,,0,2022-09-21 16:09:43,
whisper/model.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",235,238,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/model.py,6e3be77,Jong Wook Kim,initial commit,239,244,,,0,2022-09-21 16:09:43,
whisper/model.py,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",270,271,sqhao,21010ef,1,2023-11-06 18:10:30,2023-09-18 23:09:59
whisper/model.py,6e3be77,Jong Wook Kim,initial commit,248,269,,,0,2022-09-21 16:09:43,
whisper/model.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",245,247,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/model.py,6e3be77,Jong Wook Kim,initial commit,286,287,,,0,2022-09-21 16:09:43,
whisper/model.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",276,278,,,1,2023-03-06 22:00:49,
whisper/model.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",272,275,,,1,2023-03-06 23:50:37,
whisper/model.py,6e3be77,Jong Wook Kim,initial commit,289,290,,,0,2022-09-21 16:09:43,
whisper/model.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",285,285,,,1,2023-03-06 22:00:49,
whisper/model.py,eff383b,Jong Wook Kim,invoking __call__ instead of forward(),288,288,,,0,2022-11-16 12:18:50,
whisper/model.py,eff383b,Jong Wook Kim,invoking __call__ instead of forward(),291,291,,,0,2022-11-16 12:18:50,
whisper/model.py,6e3be77,Jong Wook Kim,initial commit,292,292,,,0,2022-09-21 16:09:43,
whisper/model.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",293,295,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/model.py,6e3be77,Jong Wook Kim,initial commit,296,303,,,0,2022-09-21 16:09:43,
whisper/model.py,6e3be77,Jong Wook Kim,initial commit,309,327,,,0,2022-09-21 16:09:43,
whisper/model.py,6e3be77,Jong Wook Kim,initial commit,331,345,,,0,2022-09-21 16:09:43,
whisper/model.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",279,284,,,1,2023-03-06 23:50:37,
whisper/model.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",328,330,,,1,2023-03-06 23:50:37,
whisper/model.py,21010ef,sqhao,"fix doc of TextDecoder (#1526)  Signed-off-by: haoshengqiang <haoshengqiang@xiaohongshu.com> Co-authored-by: haoshengqiang <haoshengqiang@xiaohongshu.com>",231,231,,,1,2023-09-18 23:09:59,
whisper/model.py,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",304,308,,,1,2023-11-06 18:10:30,
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,77,79,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,84,94,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,1,76,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,80,82,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,96,122,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,83,83,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,95,95,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,123,123,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,184,229,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,172,172,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,124,149,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,173,173,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,183,183,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,150,161,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,162,171,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,174,182,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,230,230,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,231,269,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,285,296,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,284,284,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,281,283,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,298,325,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,297,297,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,270,280,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,326,326,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,407,410,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,327,405,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,406,406,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,411,411,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,416,455,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,412,415,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,460,488,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,456,458,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,459,459,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,490,614,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,616,632,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,633,633,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,615,615,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,489,489,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,646,667,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,688,692,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,668,668,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,634,644,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,669,686,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,645,645,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,687,687,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,693,693,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,694,697,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,698,699,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,722,722,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,773,773,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,700,721,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,779,807,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,723,772,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,774,777,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,778,778,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,f82bc59,Jong Wook Kim,torch.concatenate -> torch.cat for compatibility,3611,3611,Jong Wook Kim,28769fc,0,2023-01-10 18:53:18,2022-12-31 17:03:42
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,878,3610,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,808,876,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,f0083e7,Umar Farooqi,"Use ndimage.median_filter instead of signal.medfilter (#812)  For a 30s long audio file which didn't have any silence, ndimage.median_filter took 7s where signa.medfilter took 30s.  Co-authored-by: Umar Farooqi <umar@paystash.com> Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",877,877,Jong Wook Kim,f82bc59,0,2023-01-17 22:43:05,2023-01-10 18:53:18
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,3680,3684,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,f0083e7,Umar Farooqi,"Use ndimage.median_filter instead of signal.medfilter (#812)  For a 30s long audio file which didn't have any silence, ndimage.median_filter took 7s where signa.medfilter took 30s.  Co-authored-by: Umar Farooqi <umar@paystash.com> Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",3613,3613,Jong Wook Kim,f82bc59,0,2023-01-17 22:43:05,2023-01-10 18:53:18
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,3612,3612,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,3614,3679,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,3685,3706,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,3708,3809,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,3707,3707,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,3814,3814,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,3810,3811,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,3812,3813,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,3815,3865,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,3866,3866,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,3881,3881,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,3899,3899,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,3867,3880,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,3882,3895,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,3896,3898,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,3903,3903,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,3901,3902,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,3900,3900,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,3920,3920,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,3904,3917,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,3918,3918,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,3919,3919,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,3925,3939,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,3924,3924,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,3921,3923,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,3940,3940,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,3941,3943,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,3948,3948,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,3949,3962,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,3944,3944,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,3945,3947,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,3964,3964,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,3963,3963,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,3967,3968,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,3965,3966,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,3970,4020,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,3969,3969,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,4022,4072,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,4073,4073,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,4021,4021,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,4074,4087,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,4089,4139,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,4088,4088,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,4140,4140,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,4208,4208,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,4141,4155,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,4157,4207,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,6e3be77,Jong Wook Kim,initial commit,4209,4228,,,0,2022-09-21 16:09:43,
notebooks/Multilingual_ASR.ipynb,28769fc,Jong Wook Kim,word-level timestamps in Multilingual_ASR notebook,4156,4156,Jong Wook Kim,6e3be77,0,2022-12-31 17:03:42,2022-09-21 16:09:43
whisper/tokenizer.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",5,5,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,2,2,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,7,7,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",3,3,Jong Wook Kim,eab8d92,1,2023-03-06 22:00:49,2023-03-06 19:32:32
whisper/tokenizer.py,839639a,Jong Wook Kim,"Use tiktoken (#1044)  * use tiktoken==0.3.0  * formatting  * tuple should be safer  * Update whisper/tokenizer.py  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>  * use tiktoken 0.3.1  * reflecting suggestions  * cleanup  * bypassing load_tiktoken_bpe to avoid blobfile dep  ---------  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>",1,1,Jong Wook Kim,b80bcf6,0,2023-03-13 09:34:16,2023-03-06 23:50:37
whisper/tokenizer.py,839639a,Jong Wook Kim,"Use tiktoken (#1044)  * use tiktoken==0.3.0  * formatting  * tuple should be safer  * Update whisper/tokenizer.py  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>  * use tiktoken 0.3.1  * reflecting suggestions  * cleanup  * bypassing load_tiktoken_bpe to avoid blobfile dep  ---------  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>",4,4,Jong Wook Kim,b80bcf6,0,2023-03-13 09:34:16,2023-03-06 23:50:37
whisper/tokenizer.py,839639a,Jong Wook Kim,"Use tiktoken (#1044)  * use tiktoken==0.3.0  * formatting  * tuple should be safer  * Update whisper/tokenizer.py  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>  * use tiktoken 0.3.1  * reflecting suggestions  * cleanup  * bypassing load_tiktoken_bpe to avoid blobfile dep  ---------  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>",6,6,Jong Wook Kim,b80bcf6,0,2023-03-13 09:34:16,2023-03-06 23:50:37
whisper/tokenizer.py,b9265e5,altryne,"Update Hebrew language code to he per IANA registry (#401)  * Update Hebrew language code to he per IANA registry  Per [IANA registry](https://www.iana.org/assignments/language-subtag-registry/language-subtag-registry), `iw` was deprecated as the code for Hebrew in 1989 and the preferred code is `he`  The correct subtag:  ``` %% Type: language Subtag: he Description: Hebrew Added: 2005-10-16 Suppress-Script: Hebr %% ```  And the deprecation ``` %% Type: language Subtag: iw Description: Hebrew Added: 2005-10-16 Deprecated: 1989-01-01 Preferred-Value: he Suppress-Script: Hebr %% ```  * Update hebrew ISO code to he  Per discussion, it's ok to make this change without backwards compatibility",31,31,Jong Wook Kim,8cf36f3,1,2022-12-07 18:45:31,2022-09-23 11:11:27
whisper/tokenizer.py,839639a,Jong Wook Kim,"Use tiktoken (#1044)  * use tiktoken==0.3.0  * formatting  * tuple should be safer  * Update whisper/tokenizer.py  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>  * use tiktoken 0.3.1  * reflecting suggestions  * cleanup  * bypassing load_tiktoken_bpe to avoid blobfile dep  ---------  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>",8,8,Jong Wook Kim,b80bcf6,0,2023-03-13 09:34:16,2023-03-06 23:50:37
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,9,30,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",127,127,Arthur Kim,8b330df,1,2023-11-06 18:10:30,2023-09-18 23:15:33
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,32,109,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",110,110,Arthur Kim,8b330df,1,2023-11-06 18:10:30,2023-09-18 23:15:33
whisper/tokenizer.py,839639a,Jong Wook Kim,"Use tiktoken (#1044)  * use tiktoken==0.3.0  * formatting  * tuple should be safer  * Update whisper/tokenizer.py  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>  * use tiktoken 0.3.1  * reflecting suggestions  * cleanup  * bypassing load_tiktoken_bpe to avoid blobfile dep  ---------  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>",131,131,Jong Wook Kim,b80bcf6,0,2023-03-13 09:34:16,2023-03-06 23:50:37
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,128,130,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,111,126,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,134,134,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,132,132,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,839639a,Jong Wook Kim,"Use tiktoken (#1044)  * use tiktoken==0.3.0  * formatting  * tuple should be safer  * Update whisper/tokenizer.py  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>  * use tiktoken 0.3.1  * reflecting suggestions  * cleanup  * bypassing load_tiktoken_bpe to avoid blobfile dep  ---------  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>",133,133,Jong Wook Kim,b80bcf6,0,2023-03-13 09:34:16,2023-03-06 23:50:37
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,160,161,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",151,151,Arthur Kim,8b330df,1,2023-11-06 18:10:30,2023-09-18 23:15:33
whisper/tokenizer.py,839639a,Jong Wook Kim,"Use tiktoken (#1044)  * use tiktoken==0.3.0  * formatting  * tuple should be safer  * Update whisper/tokenizer.py  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>  * use tiktoken 0.3.1  * reflecting suggestions  * cleanup  * bypassing load_tiktoken_bpe to avoid blobfile dep  ---------  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>",135,135,Jong Wook Kim,b80bcf6,0,2023-03-13 09:34:16,2023-03-06 23:50:37
whisper/tokenizer.py,839639a,Jong Wook Kim,"Use tiktoken (#1044)  * use tiktoken==0.3.0  * formatting  * tuple should be safer  * Update whisper/tokenizer.py  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>  * use tiktoken 0.3.1  * reflecting suggestions  * cleanup  * bypassing load_tiktoken_bpe to avoid blobfile dep  ---------  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>",152,159,Jong Wook Kim,b80bcf6,0,2023-03-13 09:34:16,2023-03-06 23:50:37
whisper/tokenizer.py,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",136,136,Arthur Kim,8b330df,1,2023-11-06 18:10:30,2023-09-18 23:15:33
whisper/tokenizer.py,839639a,Jong Wook Kim,"Use tiktoken (#1044)  * use tiktoken==0.3.0  * formatting  * tuple should be safer  * Update whisper/tokenizer.py  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>  * use tiktoken 0.3.1  * reflecting suggestions  * cleanup  * bypassing load_tiktoken_bpe to avoid blobfile dep  ---------  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>",137,150,Jong Wook Kim,b80bcf6,0,2023-03-13 09:34:16,2023-03-06 23:50:37
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,167,167,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,163,163,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,839639a,Jong Wook Kim,"Use tiktoken (#1044)  * use tiktoken==0.3.0  * formatting  * tuple should be safer  * Update whisper/tokenizer.py  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>  * use tiktoken 0.3.1  * reflecting suggestions  * cleanup  * bypassing load_tiktoken_bpe to avoid blobfile dep  ---------  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>",168,168,Jong Wook Kim,b80bcf6,0,2023-03-13 09:34:16,2023-03-06 23:50:37
whisper/tokenizer.py,839639a,Jong Wook Kim,"Use tiktoken (#1044)  * use tiktoken==0.3.0  * formatting  * tuple should be safer  * Update whisper/tokenizer.py  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>  * use tiktoken 0.3.1  * reflecting suggestions  * cleanup  * bypassing load_tiktoken_bpe to avoid blobfile dep  ---------  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>",164,166,Jong Wook Kim,b80bcf6,0,2023-03-13 09:34:16,2023-03-06 23:50:37
whisper/tokenizer.py,839639a,Jong Wook Kim,"Use tiktoken (#1044)  * use tiktoken==0.3.0  * formatting  * tuple should be safer  * Update whisper/tokenizer.py  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>  * use tiktoken 0.3.1  * reflecting suggestions  * cleanup  * bypassing load_tiktoken_bpe to avoid blobfile dep  ---------  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>",162,162,Jong Wook Kim,b80bcf6,0,2023-03-13 09:34:16,2023-03-06 23:50:37
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,169,169,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,839639a,Jong Wook Kim,"Use tiktoken (#1044)  * use tiktoken==0.3.0  * formatting  * tuple should be safer  * Update whisper/tokenizer.py  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>  * use tiktoken 0.3.1  * reflecting suggestions  * cleanup  * bypassing load_tiktoken_bpe to avoid blobfile dep  ---------  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>",170,170,Jong Wook Kim,b80bcf6,0,2023-03-13 09:34:16,2023-03-06 23:50:37
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,171,172,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,174,174,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,839639a,Jong Wook Kim,"Use tiktoken (#1044)  * use tiktoken==0.3.0  * formatting  * tuple should be safer  * Update whisper/tokenizer.py  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>  * use tiktoken 0.3.1  * reflecting suggestions  * cleanup  * bypassing load_tiktoken_bpe to avoid blobfile dep  ---------  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>",173,173,Jong Wook Kim,b80bcf6,0,2023-03-13 09:34:16,2023-03-06 23:50:37
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,176,176,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,178,178,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,a6b36ed,Jong Wook Kim,drop python 3.7 support (#889),175,175,altryne,b9265e5,0,2023-01-24 22:05:57,2022-12-07 18:45:31
whisper/tokenizer.py,839639a,Jong Wook Kim,"Use tiktoken (#1044)  * use tiktoken==0.3.0  * formatting  * tuple should be safer  * Update whisper/tokenizer.py  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>  * use tiktoken 0.3.1  * reflecting suggestions  * cleanup  * bypassing load_tiktoken_bpe to avoid blobfile dep  ---------  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>",177,177,Jong Wook Kim,b80bcf6,0,2023-03-13 09:34:16,2023-03-06 23:50:37
whisper/tokenizer.py,a6b36ed,Jong Wook Kim,drop python 3.7 support (#889),179,179,altryne,b9265e5,0,2023-01-24 22:05:57,2022-12-07 18:45:31
whisper/tokenizer.py,eab8d92,Jong Wook Kim,"Decoding improvements (#1033)  * suppress task tokens (transcribe/translate)  * not ignoring the last segment ending with one timestamp",180,180,altryne,b9265e5,0,2023-03-06 19:32:32,2022-12-07 18:45:31
whisper/tokenizer.py,eab8d92,Jong Wook Kim,"Decoding improvements (#1033)  * suppress task tokens (transcribe/translate)  * not ignoring the last segment ending with one timestamp",182,184,altryne,b9265e5,0,2023-03-06 19:32:32,2022-12-07 18:45:31
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,188,188,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,839639a,Jong Wook Kim,"Use tiktoken (#1044)  * use tiktoken==0.3.0  * formatting  * tuple should be safer  * Update whisper/tokenizer.py  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>  * use tiktoken 0.3.1  * reflecting suggestions  * cleanup  * bypassing load_tiktoken_bpe to avoid blobfile dep  ---------  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>",181,181,Jong Wook Kim,b80bcf6,0,2023-03-13 09:34:16,2023-03-06 23:50:37
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,190,190,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,192,192,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,839639a,Jong Wook Kim,"Use tiktoken (#1044)  * use tiktoken==0.3.0  * formatting  * tuple should be safer  * Update whisper/tokenizer.py  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>  * use tiktoken 0.3.1  * reflecting suggestions  * cleanup  * bypassing load_tiktoken_bpe to avoid blobfile dep  ---------  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>",185,185,Jong Wook Kim,b80bcf6,0,2023-03-13 09:34:16,2023-03-06 23:50:37
whisper/tokenizer.py,eab8d92,Jong Wook Kim,"Decoding improvements (#1033)  * suppress task tokens (transcribe/translate)  * not ignoring the last segment ending with one timestamp",186,187,altryne,b9265e5,0,2023-03-06 19:32:32,2022-12-07 18:45:31
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,194,194,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,839639a,Jong Wook Kim,"Use tiktoken (#1044)  * use tiktoken==0.3.0  * formatting  * tuple should be safer  * Update whisper/tokenizer.py  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>  * use tiktoken 0.3.1  * reflecting suggestions  * cleanup  * bypassing load_tiktoken_bpe to avoid blobfile dep  ---------  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>",189,189,Jong Wook Kim,b80bcf6,0,2023-03-13 09:34:16,2023-03-06 23:50:37
whisper/tokenizer.py,a6b36ed,Jong Wook Kim,drop python 3.7 support (#889),191,191,,,0,2023-01-24 22:05:57,
whisper/tokenizer.py,839639a,Jong Wook Kim,"Use tiktoken (#1044)  * use tiktoken==0.3.0  * formatting  * tuple should be safer  * Update whisper/tokenizer.py  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>  * use tiktoken 0.3.1  * reflecting suggestions  * cleanup  * bypassing load_tiktoken_bpe to avoid blobfile dep  ---------  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>",193,193,Jong Wook Kim,b80bcf6,0,2023-03-13 09:34:16,2023-03-06 23:50:37
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,196,196,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,198,198,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,a6b36ed,Jong Wook Kim,drop python 3.7 support (#889),195,195,,,0,2023-01-24 22:05:57,
whisper/tokenizer.py,15ab548,Jong Wook Kim,nocaptions -> nospeech to match the paper figure,200,200,,,0,2022-09-23 06:45:32,
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,202,202,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,839639a,Jong Wook Kim,"Use tiktoken (#1044)  * use tiktoken==0.3.0  * formatting  * tuple should be safer  * Update whisper/tokenizer.py  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>  * use tiktoken 0.3.1  * reflecting suggestions  * cleanup  * bypassing load_tiktoken_bpe to avoid blobfile dep  ---------  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>",197,197,Jong Wook Kim,b80bcf6,0,2023-03-13 09:34:16,2023-03-06 23:50:37
whisper/tokenizer.py,a6b36ed,Jong Wook Kim,drop python 3.7 support (#889),199,199,,,0,2023-01-24 22:05:57,
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,204,204,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,839639a,Jong Wook Kim,"Use tiktoken (#1044)  * use tiktoken==0.3.0  * formatting  * tuple should be safer  * Update whisper/tokenizer.py  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>  * use tiktoken 0.3.1  * reflecting suggestions  * cleanup  * bypassing load_tiktoken_bpe to avoid blobfile dep  ---------  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>",201,201,Jong Wook Kim,b80bcf6,0,2023-03-13 09:34:16,2023-03-06 23:50:37
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,206,206,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,208,208,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,a6b36ed,Jong Wook Kim,drop python 3.7 support (#889),203,203,altryne,b9265e5,0,2023-01-24 22:05:57,2022-12-07 18:45:31
whisper/tokenizer.py,a6b36ed,Jong Wook Kim,drop python 3.7 support (#889),207,207,altryne,b9265e5,0,2023-01-24 22:05:57,2022-12-07 18:45:31
whisper/tokenizer.py,839639a,Jong Wook Kim,"Use tiktoken (#1044)  * use tiktoken==0.3.0  * formatting  * tuple should be safer  * Update whisper/tokenizer.py  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>  * use tiktoken 0.3.1  * reflecting suggestions  * cleanup  * bypassing load_tiktoken_bpe to avoid blobfile dep  ---------  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>",209,209,Jong Wook Kim,b80bcf6,0,2023-03-13 09:34:16,2023-03-06 23:50:37
whisper/tokenizer.py,839639a,Jong Wook Kim,"Use tiktoken (#1044)  * use tiktoken==0.3.0  * formatting  * tuple should be safer  * Update whisper/tokenizer.py  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>  * use tiktoken 0.3.1  * reflecting suggestions  * cleanup  * bypassing load_tiktoken_bpe to avoid blobfile dep  ---------  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>",205,205,Jong Wook Kim,b80bcf6,0,2023-03-13 09:34:16,2023-03-06 23:50:37
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,212,214,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,a6b36ed,Jong Wook Kim,drop python 3.7 support (#889),211,211,,,0,2023-01-24 22:05:57,
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,210,210,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,216,216,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",215,215,altryne,b9265e5,1,2023-03-06 23:50:37,2022-12-07 18:45:31
whisper/tokenizer.py,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",217,220,Arthur Kim,8b330df,1,2023-11-06 18:10:30,2023-09-18 23:15:33
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,222,222,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",223,223,Arthur Kim,8b330df,1,2023-11-06 18:10:30,2023-09-18 23:15:33
whisper/tokenizer.py,839639a,Jong Wook Kim,"Use tiktoken (#1044)  * use tiktoken==0.3.0  * formatting  * tuple should be safer  * Update whisper/tokenizer.py  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>  * use tiktoken 0.3.1  * reflecting suggestions  * cleanup  * bypassing load_tiktoken_bpe to avoid blobfile dep  ---------  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>",221,221,Jong Wook Kim,b80bcf6,0,2023-03-13 09:34:16,2023-03-06 23:50:37
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,226,227,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,229,230,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,a6b36ed,Jong Wook Kim,drop python 3.7 support (#889),225,225,altryne,b9265e5,0,2023-01-24 22:05:57,2022-12-07 18:45:31
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,224,224,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,232,232,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,234,234,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,a6b36ed,Jong Wook Kim,drop python 3.7 support (#889),233,233,Jong Wook Kim,15ab548,0,2023-01-24 22:05:57,2022-09-23 06:45:32
whisper/tokenizer.py,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",231,231,Arthur Kim,8b330df,1,2023-11-06 18:10:30,2023-09-18 23:15:33
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,236,236,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",253,256,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,238,240,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,a6b36ed,Jong Wook Kim,drop python 3.7 support (#889),237,237,Jong Wook Kim,15ab548,0,2023-01-24 22:05:57,2022-09-23 06:45:32
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,242,252,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,a6b36ed,Jong Wook Kim,drop python 3.7 support (#889),241,241,,,0,2023-01-24 22:05:57,
whisper/tokenizer.py,839639a,Jong Wook Kim,"Use tiktoken (#1044)  * use tiktoken==0.3.0  * formatting  * tuple should be safer  * Update whisper/tokenizer.py  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>  * use tiktoken 0.3.1  * reflecting suggestions  * cleanup  * bypassing load_tiktoken_bpe to avoid blobfile dep  ---------  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>",228,228,altryne,b9265e5,0,2023-03-13 09:34:16,2022-12-07 18:45:31
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,257,264,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,267,267,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,839639a,Jong Wook Kim,"Use tiktoken (#1044)  * use tiktoken==0.3.0  * formatting  * tuple should be safer  * Update whisper/tokenizer.py  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>  * use tiktoken 0.3.1  * reflecting suggestions  * cleanup  * bypassing load_tiktoken_bpe to avoid blobfile dep  ---------  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>",266,266,Jong Wook Kim,b80bcf6,0,2023-03-13 09:34:16,2023-03-06 23:50:37
whisper/tokenizer.py,8cf36f3,Jong Wook Kim,allow hyphens and single quotes between words,265,265,,,0,2022-09-23 11:11:27,
whisper/tokenizer.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",268,268,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/tokenizer.py,839639a,Jong Wook Kim,"Use tiktoken (#1044)  * use tiktoken==0.3.0  * formatting  * tuple should be safer  * Update whisper/tokenizer.py  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>  * use tiktoken 0.3.1  * reflecting suggestions  * cleanup  * bypassing load_tiktoken_bpe to avoid blobfile dep  ---------  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>",269,270,Jong Wook Kim,b80bcf6,0,2023-03-13 09:34:16,2023-03-06 23:50:37
whisper/tokenizer.py,8b330df,Arthur Kim,"Add .pre-commit-config.yaml (#1528)  * Add .pre-commit-config.yaml  Co-authored-by: arthur <arthur@rtzr.ai>  * flake8 E741  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",235,235,altryne,b9265e5,0,2023-09-18 23:15:33,2022-12-07 18:45:31
whisper/tokenizer.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",277,277,Jong Wook Kim,eab8d92,1,2023-03-06 22:00:49,2023-03-06 19:32:32
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,272,276,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",278,278,Arthur Kim,8b330df,1,2023-11-06 18:10:30,2023-09-18 23:15:33
whisper/tokenizer.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",290,292,Jong Wook Kim,eab8d92,1,2023-03-06 22:00:49,2023-03-06 19:32:32
whisper/tokenizer.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",279,286,Jong Wook Kim,eab8d92,1,2023-03-06 22:00:49,2023-03-06 19:32:32
whisper/tokenizer.py,5f9ac65,Guillaume Klein,Fix truncated words list when the replacement character is decoded (#1089),287,289,Jong Wook Kim,839639a,1,2023-03-14 16:32:41,2023-03-13 09:34:16
whisper/tokenizer.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",304,306,Jong Wook Kim,eab8d92,1,2023-03-06 22:00:49,2023-03-06 19:32:32
whisper/tokenizer.py,5f9ac65,Guillaume Klein,Fix truncated words list when the replacement character is decoded (#1089),293,293,Jong Wook Kim,839639a,1,2023-03-14 16:32:41,2023-03-13 09:34:16
whisper/tokenizer.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",271,271,,,1,2023-03-06 23:50:37,
whisper/tokenizer.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",294,297,Jong Wook Kim,eab8d92,1,2023-03-06 22:00:49,2023-03-06 19:32:32
whisper/tokenizer.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",308,328,Jong Wook Kim,eab8d92,1,2023-03-06 22:00:49,2023-03-06 19:32:32
whisper/tokenizer.py,5f9ac65,Guillaume Klein,Fix truncated words list when the replacement character is decoded (#1089),298,303,Jong Wook Kim,839639a,1,2023-03-14 16:32:41,2023-03-13 09:34:16
whisper/tokenizer.py,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",331,331,Arthur Kim,8b330df,1,2023-11-06 18:10:30,2023-09-18 23:15:33
whisper/tokenizer.py,839639a,Jong Wook Kim,"Use tiktoken (#1044)  * use tiktoken==0.3.0  * formatting  * tuple should be safer  * Update whisper/tokenizer.py  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>  * use tiktoken 0.3.1  * reflecting suggestions  * cleanup  * bypassing load_tiktoken_bpe to avoid blobfile dep  ---------  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>",332,338,Jong Wook Kim,b80bcf6,0,2023-03-13 09:34:16,2023-03-06 23:50:37
whisper/tokenizer.py,5f9ac65,Guillaume Klein,Fix truncated words list when the replacement character is decoded (#1089),307,307,Jong Wook Kim,eab8d92,1,2023-03-14 16:32:41,2023-03-06 19:32:32
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,339,340,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,329,330,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,342,342,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,839639a,Jong Wook Kim,"Use tiktoken (#1044)  * use tiktoken==0.3.0  * formatting  * tuple should be safer  * Update whisper/tokenizer.py  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>  * use tiktoken 0.3.1  * reflecting suggestions  * cleanup  * bypassing load_tiktoken_bpe to avoid blobfile dep  ---------  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>",341,341,Jong Wook Kim,b80bcf6,0,2023-03-13 09:34:16,2023-03-06 23:50:37
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,344,347,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",343,343,Arthur Kim,8b330df,1,2023-11-06 18:10:30,2023-09-18 23:15:33
whisper/tokenizer.py,15ab548,Jong Wook Kim,nocaptions -> nospeech to match the paper figure,348,348,,,0,2022-09-23 06:45:32,
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,349,349,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,351,352,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,839639a,Jong Wook Kim,"Use tiktoken (#1044)  * use tiktoken==0.3.0  * formatting  * tuple should be safer  * Update whisper/tokenizer.py  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>  * use tiktoken 0.3.1  * reflecting suggestions  * cleanup  * bypassing load_tiktoken_bpe to avoid blobfile dep  ---------  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>",350,350,Jong Wook Kim,b80bcf6,0,2023-03-13 09:34:16,2023-03-06 23:50:37
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,364,369,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",370,370,Arthur Kim,8b330df,1,2023-11-06 18:10:30,2023-09-18 23:15:33
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,371,371,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,839639a,Jong Wook Kim,"Use tiktoken (#1044)  * use tiktoken==0.3.0  * formatting  * tuple should be safer  * Update whisper/tokenizer.py  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>  * use tiktoken 0.3.1  * reflecting suggestions  * cleanup  * bypassing load_tiktoken_bpe to avoid blobfile dep  ---------  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>",353,359,Jong Wook Kim,b80bcf6,0,2023-03-13 09:34:16,2023-03-06 23:50:37
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,373,382,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,839639a,Jong Wook Kim,"Use tiktoken (#1044)  * use tiktoken==0.3.0  * formatting  * tuple should be safer  * Update whisper/tokenizer.py  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>  * use tiktoken 0.3.1  * reflecting suggestions  * cleanup  * bypassing load_tiktoken_bpe to avoid blobfile dep  ---------  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>",372,372,Jong Wook Kim,b80bcf6,0,2023-03-13 09:34:16,2023-03-06 23:50:37
whisper/tokenizer.py,b5851c6,Jong Wook Kim,Update tokenizer.py (#1163),360,360,Jong Wook Kim,b80bcf6,0,2023-03-29 20:12:36,2023-03-06 23:50:37
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,384,384,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,386,386,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,390,390,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,388,388,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",393,395,Arthur Kim,8b330df,1,2023-11-06 18:10:30,2023-09-18 23:15:33
whisper/tokenizer.py,839639a,Jong Wook Kim,"Use tiktoken (#1044)  * use tiktoken==0.3.0  * formatting  * tuple should be safer  * Update whisper/tokenizer.py  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>  * use tiktoken 0.3.1  * reflecting suggestions  * cleanup  * bypassing load_tiktoken_bpe to avoid blobfile dep  ---------  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>",361,363,,,0,2023-03-13 09:34:16,
whisper/tokenizer.py,6e3be77,Jong Wook Kim,initial commit,392,392,,,0,2022-09-21 16:09:43,
whisper/tokenizer.py,839639a,Jong Wook Kim,"Use tiktoken (#1044)  * use tiktoken==0.3.0  * formatting  * tuple should be safer  * Update whisper/tokenizer.py  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>  * use tiktoken 0.3.1  * reflecting suggestions  * cleanup  * bypassing load_tiktoken_bpe to avoid blobfile dep  ---------  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>",387,387,,,0,2023-03-13 09:34:16,
whisper/tokenizer.py,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",391,391,Arthur Kim,8b330df,1,2023-11-06 18:10:30,2023-09-18 23:15:33
whisper/tokenizer.py,839639a,Jong Wook Kim,"Use tiktoken (#1044)  * use tiktoken==0.3.0  * formatting  * tuple should be safer  * Update whisper/tokenizer.py  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>  * use tiktoken 0.3.1  * reflecting suggestions  * cleanup  * bypassing load_tiktoken_bpe to avoid blobfile dep  ---------  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>",385,385,,,0,2023-03-13 09:34:16,
whisper/tokenizer.py,839639a,Jong Wook Kim,"Use tiktoken (#1044)  * use tiktoken==0.3.0  * formatting  * tuple should be safer  * Update whisper/tokenizer.py  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>  * use tiktoken 0.3.1  * reflecting suggestions  * cleanup  * bypassing load_tiktoken_bpe to avoid blobfile dep  ---------  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>",383,383,,,0,2023-03-13 09:34:16,
whisper/tokenizer.py,839639a,Jong Wook Kim,"Use tiktoken (#1044)  * use tiktoken==0.3.0  * formatting  * tuple should be safer  * Update whisper/tokenizer.py  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>  * use tiktoken 0.3.1  * reflecting suggestions  * cleanup  * bypassing load_tiktoken_bpe to avoid blobfile dep  ---------  Co-authored-by: Ruhollah Majdoddin <r.majdodin@gmail.com>",389,389,,,0,2023-03-13 09:34:16,
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,3,18,,,0,2022-09-21 16:09:43,
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,22,34,,,0,2022-09-21 16:09:43,
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",19,21,Jong Wook Kim,eab8d92,1,2023-03-06 23:50:37,2023-03-06 19:32:32
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",2,2,Jong Wook Kim,eab8d92,1,2023-03-06 23:50:37,2023-03-06 19:32:32
whisper/decoding.py,c4b50c0,Jong Wook Kim,"kwargs in decode() for convenience (#1061)  * kwargs in decode() for convenience  * formatting fix",1,1,Jong Wook Kim,b80bcf6,1,2023-03-08 23:46:38,2023-03-06 23:50:37
whisper/decoding.py,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",35,37,WangChou Lu,b91c907,1,2023-11-06 18:10:30,2023-07-06 19:48:08
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,45,81,,,0,2022-09-21 16:09:43,
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",38,44,Jong Wook Kim,eab8d92,1,2023-03-06 23:50:37,2023-03-06 19:32:32
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",82,86,Jong Wook Kim,eab8d92,1,2023-03-06 23:50:37,2023-03-06 19:32:32
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,87,90,,,0,2022-09-21 16:09:43,
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",91,93,Jong Wook Kim,eab8d92,1,2023-03-06 23:50:37,2023-03-06 19:32:32
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,94,94,,,0,2022-09-21 16:09:43,
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",95,97,Jong Wook Kim,eab8d92,1,2023-03-06 23:50:37,2023-03-06 19:32:32
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,98,98,,,0,2022-09-21 16:09:43,
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,103,106,,,0,2022-09-21 16:09:43,
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",99,102,Jong Wook Kim,eab8d92,1,2023-03-06 23:50:37,2023-03-06 19:32:32
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,108,109,,,0,2022-09-21 16:09:43,
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",110,111,Jong Wook Kim,eab8d92,1,2023-03-06 23:50:37,2023-03-06 19:32:32
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",107,107,Jong Wook Kim,eab8d92,1,2023-03-06 23:50:37,2023-03-06 19:32:32
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,112,124,,,0,2022-09-21 16:09:43,
whisper/decoding.py,15ab548,Jong Wook Kim,nocaptions -> nospeech to match the paper figure,125,125,,,0,2022-09-23 06:45:32,
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,126,150,,,0,2022-09-21 16:09:43,
whisper/decoding.py,b91c907,WangChou Lu,"Avoid rearranging all caches (#1483)  * avoid rearranging all kv_caches  * avoid calculating the same kv_cache from cross attn  * Update decoding.py  * linter fix  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",151,154,Jong Wook Kim,c09a7ae,1,2023-07-06 19:48:08,2023-04-11 22:13:13
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,177,179,,,0,2022-09-21 16:09:43,
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,183,219,,,0,2022-09-21 16:09:43,
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,155,172,,,0,2022-09-21 16:09:43,
whisper/decoding.py,b91c907,WangChou Lu,"Avoid rearranging all caches (#1483)  * avoid rearranging all kv_caches  * avoid calculating the same kv_cache from cross attn  * Update decoding.py  * linter fix  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",173,176,Jong Wook Kim,c09a7ae,1,2023-07-06 19:48:08,2023-04-11 22:13:13
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,223,276,,,0,2022-09-21 16:09:43,
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,281,282,,,0,2022-09-21 16:09:43,
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",302,308,Jong Wook Kim,eab8d92,1,2023-03-06 23:50:37,2023-03-06 19:32:32
whisper/decoding.py,a6b36ed,Jong Wook Kim,drop python 3.7 support (#889),283,283,VulumeCode,520796a,0,2023-01-24 22:05:57,2022-09-26 11:35:21
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,284,301,,,0,2022-09-21 16:09:43,
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",277,279,jumon,76148a5,1,2023-03-06 23:50:37,2022-11-15 19:44:36
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,309,311,,,0,2022-09-21 16:09:43,
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,314,315,,,0,2022-09-21 16:09:43,
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",220,222,,,1,2023-03-06 23:50:37,
whisper/decoding.py,62fe7f1,Jong Wook Kim,patience definition to match the paper,312,313,,,0,2022-09-28 02:00:41,
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",180,182,,,1,2023-03-06 23:50:37,
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,320,322,,,0,2022-09-21 16:09:43,
whisper/decoding.py,a6b36ed,Jong Wook Kim,drop python 3.7 support (#889),280,280,VulumeCode,520796a,0,2023-01-24 22:05:57,2022-09-26 11:35:21
whisper/decoding.py,62fe7f1,Jong Wook Kim,patience definition to match the paper,319,319,,,0,2022-09-28 02:00:41,
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",316,318,Jong Wook Kim,eab8d92,1,2023-03-06 23:50:37,2023-03-06 19:32:32
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,326,368,,,0,2022-09-21 16:09:43,
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",379,380,Jong Wook Kim,eab8d92,1,2023-03-06 23:50:37,2023-03-06 19:32:32
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,372,378,,,0,2022-09-21 16:09:43,
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",369,371,Jong Wook Kim,eab8d92,1,2023-03-06 23:50:37,2023-03-06 19:32:32
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",388,390,Jong Wook Kim,eab8d92,1,2023-03-06 23:50:37,2023-03-06 19:32:32
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,381,387,,,0,2022-09-21 16:09:43,
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,391,397,,,0,2022-09-21 16:09:43,
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,400,442,,,0,2022-09-21 16:09:43,
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,447,458,,,0,2022-09-21 16:09:43,
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",323,325,,,1,2023-03-06 23:50:37,
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",474,476,Jong Wook Kim,a6b36ed,1,2023-03-06 23:50:37,2023-01-24 22:05:57
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,467,473,,,0,2022-09-21 16:09:43,
whisper/decoding.py,c09a7ae,Jong Wook Kim,Update decoding.py (#1219),479,479,Jong Wook Kim,c4b50c0,0,2023-04-11 22:13:13,2023-03-08 23:46:38
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",398,399,,,1,2023-03-06 23:50:37,
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",461,466,Jong Wook Kim,eab8d92,1,2023-03-06 23:50:37,2023-03-06 19:32:32
whisper/decoding.py,7858aa9,Andrey Chernykh,"Fix infinite loop caused by incorrect timestamp tokens prediction (#914)  * Fix infinite loop caused by incorrect timestamp tokens prediction  https://github.com/openai/whisper/discussions/810  * Update decoding.py  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",459,460,,,1,2023-02-01 23:46:51,
whisper/decoding.py,b0022b3,Fernando O. Gallego,"Update decoding.py (#1155)  * Update decoding.py  Following the suggestions of @Jeronymous in https://github.com/openai/whisper/pull/914 and https://github.com/openai/whisper/discussions/924, it solves the problem of endless loop.  * Removed blank line and whitespaces in empty lines.  * Suggested changes according to the linter  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",480,485,Jong Wook Kim,c4b50c0,0,2023-04-11 22:06:03,2023-03-08 23:46:38
whisper/decoding.py,76148a5,jumon,suppress generating non-timestamp tokens at the beginning (#532),486,491,,,0,2022-11-15 19:44:36,
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",492,494,Jong Wook Kim,eab8d92,1,2023-03-06 23:50:37,2023-03-06 19:32:32
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,503,517,,,0,2022-09-21 16:09:43,
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",443,446,,,1,2023-03-06 23:50:37,
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,496,499,,,0,2022-09-21 16:09:43,
whisper/decoding.py,76148a5,jumon,suppress generating non-timestamp tokens at the beginning (#532),495,495,,,0,2022-11-15 19:44:36,
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,524,562,,,0,2022-09-21 16:09:43,
whisper/decoding.py,7858aa9,Andrey Chernykh,"Fix infinite loop caused by incorrect timestamp tokens prediction (#914)  * Fix infinite loop caused by incorrect timestamp tokens prediction  https://github.com/openai/whisper/discussions/810  * Update decoding.py  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",477,478,,,1,2023-02-01 23:46:51,
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",563,565,Jong Wook Kim,eab8d92,1,2023-03-06 23:50:37,2023-03-06 19:32:32
whisper/decoding.py,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",519,522,WangChou Lu,b91c907,1,2023-11-06 18:10:30,2023-07-06 19:48:08
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,566,566,,,0,2022-09-21 16:09:43,
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,570,577,,,0,2022-09-21 16:09:43,
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",580,582,Jong Wook Kim,eab8d92,1,2023-03-06 23:50:37,2023-03-06 19:32:32
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,583,588,,,0,2022-09-21 16:09:43,
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",567,569,Jong Wook Kim,eab8d92,1,2023-03-06 23:50:37,2023-03-06 19:32:32
whisper/decoding.py,62fe7f1,Jong Wook Kim,patience definition to match the paper,578,579,,,0,2022-09-28 02:00:41,
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",518,518,,,1,2023-03-06 23:50:37,
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,595,600,,,0,2022-09-21 16:09:43,
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",523,523,,,1,2023-03-06 23:50:37,
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,589,589,,,0,2022-09-21 16:09:43,
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",500,502,,,1,2023-03-06 23:50:37,
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,591,591,,,0,2022-09-21 16:09:43,
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",592,594,Jong Wook Kim,eab8d92,1,2023-03-06 23:50:37,2023-03-06 19:32:32
whisper/decoding.py,a6b36ed,Jong Wook Kim,drop python 3.7 support (#889),590,590,Jong Wook Kim,6e3be77,0,2023-01-24 22:05:57,2022-09-21 16:09:43
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,602,602,,,0,2022-09-21 16:09:43,
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,611,611,,,0,2022-09-21 16:09:43,
whisper/decoding.py,520796a,VulumeCode,fix token suppression (#123),627,627,,,1,2022-09-26 11:35:21,
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,612,626,,,0,2022-09-21 16:09:43,
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,628,629,,,0,2022-09-21 16:09:43,
whisper/decoding.py,eab8d92,Jong Wook Kim,"Decoding improvements (#1033)  * suppress task tokens (transcribe/translate)  * not ignoring the last segment ending with one timestamp",630,634,Jong Wook Kim,7cb4cc2,0,2023-03-06 19:32:32,2022-09-30 01:05:12
whisper/decoding.py,a6b36ed,Jong Wook Kim,drop python 3.7 support (#889),601,601,,,0,2023-01-24 22:05:57,
whisper/decoding.py,15ab548,Jong Wook Kim,nocaptions -> nospeech to match the paper figure,638,640,Jong Wook Kim,6e3be77,0,2022-09-23 06:45:32,2022-09-21 16:09:43
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,637,637,,,0,2022-09-21 16:09:43,
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",635,635,Jong Wook Kim,eab8d92,1,2023-03-06 23:50:37,2023-03-06 19:32:32
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",603,610,Jong Wook Kim,15ab548,1,2023-03-06 23:50:37,2022-09-23 06:45:32
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",648,651,Jong Wook Kim,eab8d92,1,2023-03-06 23:50:37,2023-03-06 19:32:32
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,641,647,,,0,2022-09-21 16:09:43,
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,663,670,,,0,2022-09-21 16:09:43,
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,652,656,,,0,2022-09-21 16:09:43,
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",657,662,Jong Wook Kim,eab8d92,1,2023-03-06 23:50:37,2023-03-06 19:32:32
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",671,673,Jong Wook Kim,eab8d92,1,2023-03-06 23:50:37,2023-03-06 19:32:32
whisper/decoding.py,eab8d92,Jong Wook Kim,"Decoding improvements (#1033)  * suppress task tokens (transcribe/translate)  * not ignoring the last segment ending with one timestamp",636,636,,,0,2023-03-06 19:32:32,
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,681,682,,,0,2022-09-21 16:09:43,
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,674,680,,,0,2022-09-21 16:09:43,
whisper/decoding.py,15ab548,Jong Wook Kim,nocaptions -> nospeech to match the paper figure,683,683,,,0,2022-09-23 06:45:32,
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,684,688,,,0,2022-09-21 16:09:43,
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,694,709,,,0,2022-09-21 16:09:43,
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,692,692,,,0,2022-09-21 16:09:43,
whisper/decoding.py,15ab548,Jong Wook Kim,nocaptions -> nospeech to match the paper figure,693,693,,,0,2022-09-23 06:45:32,
whisper/decoding.py,15ab548,Jong Wook Kim,nocaptions -> nospeech to match the paper figure,710,710,,,0,2022-09-23 06:45:32,
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,711,718,,,0,2022-09-21 16:09:43,
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,720,724,,,0,2022-09-21 16:09:43,
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,731,732,,,0,2022-09-21 16:09:43,
whisper/decoding.py,9e653bd,Corentin Jemine,Fixed CoW RuntimeError in DecodingTask.run() (#240),719,719,,,1,2022-10-04 15:49:31,
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,734,736,,,0,2022-09-21 16:09:43,
whisper/decoding.py,15ab548,Jong Wook Kim,nocaptions -> nospeech to match the paper figure,741,742,,,0,2022-09-23 06:45:32,
whisper/decoding.py,15ab548,Jong Wook Kim,nocaptions -> nospeech to match the paper figure,737,737,,,0,2022-09-23 06:45:32,
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,738,740,,,0,2022-09-21 16:09:43,
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,743,749,,,0,2022-09-21 16:09:43,
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",750,751,Jong Wook Kim,eab8d92,1,2023-03-06 23:50:37,2023-03-06 19:32:32
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,752,759,,,0,2022-09-21 16:09:43,
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",760,762,Jong Wook Kim,eab8d92,1,2023-03-06 23:50:37,2023-03-06 19:32:32
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,772,781,,,0,2022-09-21 16:09:43,
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",725,730,Jong Wook Kim,6e3be77,1,2023-03-06 23:50:37,2022-09-21 16:09:43
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",689,691,,,1,2023-03-06 23:50:37,
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,763,763,,,0,2022-09-21 16:09:43,
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,783,785,,,0,2022-09-21 16:09:43,
whisper/decoding.py,15ab548,Jong Wook Kim,nocaptions -> nospeech to match the paper figure,782,782,,,0,2022-09-23 06:45:32,
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,789,792,,,0,2022-09-21 16:09:43,
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",764,771,Jong Wook Kim,eab8d92,1,2023-03-06 23:50:37,2023-03-06 19:32:32
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",786,788,,,1,2023-03-06 23:50:37,
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",798,798,,,1,2023-03-06 23:50:37,
whisper/decoding.py,c4b50c0,Jong Wook Kim,"kwargs in decode() for convenience (#1061)  * kwargs in decode() for convenience  * formatting fix",794,797,,,1,2023-03-08 23:46:38,
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,799,817,,,0,2022-09-21 16:09:43,
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,824,824,,,0,2022-09-21 16:09:43,
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,819,820,,,0,2022-09-21 16:09:43,
whisper/decoding.py,6e3be77,Jong Wook Kim,initial commit,825,825,,,0,2022-09-21 16:09:43,
whisper/decoding.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",793,793,,,1,2023-03-06 23:50:37,
whisper/decoding.py,c4b50c0,Jong Wook Kim,"kwargs in decode() for convenience (#1061)  * kwargs in decode() for convenience  * formatting fix",821,823,,,1,2023-03-08 23:46:38,
whisper/decoding.py,a6b36ed,Jong Wook Kim,drop python 3.7 support (#889),818,818,,,0,2023-01-24 22:05:57,
whisper/decoding.py,a6b36ed,Jong Wook Kim,drop python 3.7 support (#889),826,826,,,0,2023-01-24 22:05:57,
whisper/decoding.py,b91c907,WangChou Lu,"Avoid rearranging all caches (#1483)  * avoid rearranging all kv_caches  * avoid calculating the same kv_cache from cross attn  * Update decoding.py  * linter fix  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",733,733,Jong Wook Kim,6e3be77,1,2023-07-06 19:48:08,2022-09-21 16:09:43
whisper/utils.py,6e3be77,Jong Wook Kim,initial commit,7,7,,,0,2022-09-21 16:09:43,
whisper/utils.py,da600ab,Aaryan YVS,"Added --output_format option (#333)  * Added --output option  --output option will help select the output files that will be generated.  Corrected the logic, which wrongly shows progress bar when verbose is set to False  * Changed output_files variable  * Changed back the tqdm verbose  * refactor output format handling  Co-authored-by: Jong Wook Kim <jongwook@openai.com> Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",1,2,jumon,ec1b34b,0,2023-01-22 07:58:38,2022-12-04 23:27:42
whisper/utils.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",11,11,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/utils.py,ba3f3cd,ryanheise,"Skip silence around hallucinations (#1838)  * Add clip_timestamps option  * Add hallucination_silence_threshold option  * Fix typing for python < 3.9  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",6,6,amosal,6ed314f,1,2023-12-18 20:11:16,2023-11-06 09:49:33
whisper/utils.py,7f1ef22,Jong Wook Kim,handle printing even if sys.stdout.buffer is not available (#887),4,4,Niels Mayer,f5bfe00,0,2023-01-24 18:12:04,2023-01-22 08:27:17
whisper/utils.py,7f1ef22,Jong Wook Kim,handle printing even if sys.stdout.buffer is not available (#887),8,10,Niels Mayer,f5bfe00,0,2023-01-24 18:12:04,2023-01-22 08:27:17
whisper/utils.py,6e3be77,Jong Wook Kim,initial commit,5,5,,,0,2022-09-21 16:09:43,
whisper/utils.py,43940fc,ryanheise,"Implement max line width and max line count, and make word highlighting optional (#1184)  * Add highlight_words, max_line_width, max_line_count  * Refactor subtitle generator  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",3,3,Local State,c6e4e5e,0,2023-04-11 00:28:35,2023-03-07 01:48:14
whisper/utils.py,7f1ef22,Jong Wook Kim,handle printing even if sys.stdout.buffer is not available (#887),12,15,Niels Mayer,f5bfe00,0,2023-01-24 18:12:04,2023-01-22 08:27:17
whisper/utils.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",16,16,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/utils.py,7f1ef22,Jong Wook Kim,handle printing even if sys.stdout.buffer is not available (#887),17,17,Niels Mayer,f5bfe00,0,2023-01-24 18:12:04,2023-01-22 08:27:17
whisper/utils.py,6e3be77,Jong Wook Kim,initial commit,23,45,,,0,2022-09-21 16:09:43,
whisper/utils.py,7f1ef22,Jong Wook Kim,handle printing even if sys.stdout.buffer is not available (#887),19,22,Niels Mayer,f5bfe00,0,2023-01-24 18:12:04,2023-01-22 08:27:17
whisper/utils.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",50,52,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/utils.py,6e3be77,Jong Wook Kim,initial commit,48,49,,,0,2022-09-21 16:09:43,
whisper/utils.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",18,18,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/utils.py,ec1b34b,jumon,fix compression ratio function (#561),46,47,Caleb McQuillin,60132ad,1,2022-12-04 23:27:42,2022-09-30 03:44:12
whisper/utils.py,6e3be77,Jong Wook Kim,initial commit,53,64,,,0,2022-09-21 16:09:43,
whisper/utils.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",66,68,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/utils.py,02b7430,Tom Stuart,"Fix timestamps and strip extraneous whitespace in WebVTT output (#219)  * Use two-digit hours in WebVTT timestamps  Per the WebVTT specification [0]:  > A WebVTT timestamp consists of the following components, in the given > order: > > 1. Optionally (required if hours is non-zero): >   1. Two or more ASCII digits, representing the hours as a base ten >      integer. >   2. A U+003A COLON character (:)  YouTube won’t accept timestamps containing single-digit hours.  [0] https://www.w3.org/TR/webvtt1/#webvtt-timestamp  * Strip segment text in WebVTT output  We already do this for plain text and SubRip output, so we should do it for WebVTT too.",65,65,Jong Wook Kim,6e3be77,1,2022-10-03 21:51:07,2022-09-21 16:09:43
whisper/utils.py,6e3be77,Jong Wook Kim,initial commit,69,70,,,0,2022-09-21 16:09:43,
whisper/utils.py,ba3f3cd,ryanheise,"Skip silence around hallucinations (#1838)  * Add clip_timestamps option  * Add hallucination_silence_threshold option  * Fix typing for python < 3.9  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",71,84,amosal,6ed314f,1,2023-12-18 20:11:16,2023-11-06 09:49:33
whisper/utils.py,da600ab,Aaryan YVS,"Added --output_format option (#333)  * Added --output option  --output option will help select the output files that will be generated.  Corrected the logic, which wrongly shows progress bar when verbose is set to False  * Changed output_files variable  * Changed back the tqdm verbose  * refactor output format handling  Co-authored-by: Jong Wook Kim <jongwook@openai.com> Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",85,90,jumon,ec1b34b,0,2023-01-22 07:58:38,2022-12-04 23:27:42
whisper/utils.py,da600ab,Aaryan YVS,"Added --output_format option (#333)  * Added --output option  --output option will help select the output files that will be generated.  Corrected the logic, which wrongly shows progress bar when verbose is set to False  * Changed output_files variable  * Changed back the tqdm verbose  * refactor output format handling  Co-authored-by: Jong Wook Kim <jongwook@openai.com> Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",94,94,jumon,ec1b34b,0,2023-01-22 07:58:38,2022-12-04 23:27:42
whisper/utils.py,6ed314f,amosal,"Add new option to generate subtitles by a specific number of words (#1729)  * ADD parser for new argument --max_words_count  * ADD max_words_count in words_options ADD warning for max_line_width compatibility  * ADD logic for max_words_count  * rename to max_words_per_line  * make them kwargs  * allow specifying file path by --model  * black formatting  ---------  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",91,93,Jordi Mas,b38a1f2,0,2023-11-06 09:49:33,2023-10-10 17:01:01
whisper/utils.py,6ed314f,amosal,"Add new option to generate subtitles by a specific number of words (#1729)  * ADD parser for new argument --max_words_count  * ADD max_words_count in words_options ADD warning for max_line_width compatibility  * ADD logic for max_words_count  * rename to max_words_per_line  * make them kwargs  * allow specifying file path by --model  * black formatting  ---------  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",101,101,Jordi Mas,b38a1f2,0,2023-11-06 09:49:33,2023-10-10 17:01:01
whisper/utils.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",96,98,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/utils.py,c6e4e5e,Local State,remove auxiliary audio extension (#1021)  Co-authored-by: Jong Wook Kim <jongwook@openai.com>,95,95,Jong Wook Kim,500d0fe,0,2023-03-07 01:48:14,2023-03-06 22:00:49
whisper/utils.py,da600ab,Aaryan YVS,"Added --output_format option (#333)  * Added --output option  --output option will help select the output files that will be generated.  Corrected the logic, which wrongly shows progress bar when verbose is set to False  * Changed output_files variable  * Changed back the tqdm verbose  * refactor output format handling  Co-authored-by: Jong Wook Kim <jongwook@openai.com> Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",99,100,jumon,ec1b34b,0,2023-01-22 07:58:38,2022-12-04 23:27:42
whisper/utils.py,da600ab,Aaryan YVS,"Added --output_format option (#333)  * Added --output option  --output option will help select the output files that will be generated.  Corrected the logic, which wrongly shows progress bar when verbose is set to False  * Changed output_files variable  * Changed back the tqdm verbose  * refactor output format handling  Co-authored-by: Jong Wook Kim <jongwook@openai.com> Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",102,102,jumon,ec1b34b,0,2023-01-22 07:58:38,2022-12-04 23:27:42
whisper/utils.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",119,122,Jong Wook Kim,7f1ef22,1,2023-03-06 22:00:49,2023-01-24 18:12:04
whisper/utils.py,da600ab,Aaryan YVS,"Added --output_format option (#333)  * Added --output option  --output option will help select the output files that will be generated.  Corrected the logic, which wrongly shows progress bar when verbose is set to False  * Changed output_files variable  * Changed back the tqdm verbose  * refactor output format handling  Co-authored-by: Jong Wook Kim <jongwook@openai.com> Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",106,111,jumon,ec1b34b,0,2023-01-22 07:58:38,2022-12-04 23:27:42
whisper/utils.py,6ed314f,amosal,"Add new option to generate subtitles by a specific number of words (#1729)  * ADD parser for new argument --max_words_count  * ADD max_words_count in words_options ADD warning for max_line_width compatibility  * ADD logic for max_words_count  * rename to max_words_per_line  * make them kwargs  * allow specifying file path by --model  * black formatting  ---------  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",103,105,Jordi Mas,b38a1f2,0,2023-11-06 09:49:33,2023-10-10 17:01:01
whisper/utils.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",116,116,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/utils.py,da600ab,Aaryan YVS,"Added --output_format option (#333)  * Added --output option  --output option will help select the output files that will be generated.  Corrected the logic, which wrongly shows progress bar when verbose is set to False  * Changed output_files variable  * Changed back the tqdm verbose  * refactor output format handling  Co-authored-by: Jong Wook Kim <jongwook@openai.com> Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",115,115,jumon,ec1b34b,0,2023-01-22 07:58:38,2022-12-04 23:27:42
whisper/utils.py,6ed314f,amosal,"Add new option to generate subtitles by a specific number of words (#1729)  * ADD parser for new argument --max_words_count  * ADD max_words_count in words_options ADD warning for max_line_width compatibility  * ADD logic for max_words_count  * rename to max_words_per_line  * make them kwargs  * allow specifying file path by --model  * black formatting  ---------  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",112,114,Jordi Mas,b38a1f2,0,2023-11-06 09:49:33,2023-10-10 17:01:01
whisper/utils.py,6ed314f,amosal,"Add new option to generate subtitles by a specific number of words (#1729)  * ADD parser for new argument --max_words_count  * ADD max_words_count in words_options ADD warning for max_line_width compatibility  * ADD logic for max_words_count  * rename to max_words_per_line  * make them kwargs  * allow specifying file path by --model  * black formatting  ---------  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",123,140,Jordi Mas,b38a1f2,0,2023-11-06 09:49:33,2023-10-10 17:01:01
whisper/utils.py,da600ab,Aaryan YVS,"Added --output_format option (#333)  * Added --output option  --output option will help select the output files that will be generated.  Corrected the logic, which wrongly shows progress bar when verbose is set to False  * Changed output_files variable  * Changed back the tqdm verbose  * refactor output format handling  Co-authored-by: Jong Wook Kim <jongwook@openai.com> Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",117,118,jumon,ec1b34b,0,2023-01-22 07:58:38,2022-12-04 23:27:42
whisper/utils.py,ba3f3cd,ryanheise,"Skip silence around hallucinations (#1838)  * Add clip_timestamps option  * Add hallucination_silence_threshold option  * Fix typing for python < 3.9  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",146,147,amosal,6ed314f,1,2023-12-18 20:11:16,2023-11-06 09:49:33
whisper/utils.py,43940fc,ryanheise,"Implement max line width and max line count, and make word highlighting optional (#1184)  * Add highlight_words, max_line_width, max_line_count  * Refactor subtitle generator  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",148,148,Local State,c6e4e5e,0,2023-04-11 00:28:35,2023-03-07 01:48:14
whisper/utils.py,43940fc,ryanheise,"Implement max line width and max line count, and make word highlighting optional (#1184)  * Add highlight_words, max_line_width, max_line_count  * Refactor subtitle generator  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",141,145,Local State,c6e4e5e,0,2023-04-11 00:28:35,2023-03-07 01:48:14
whisper/utils.py,6ed314f,amosal,"Add new option to generate subtitles by a specific number of words (#1729)  * ADD parser for new argument --max_words_count  * ADD max_words_count in words_options ADD warning for max_line_width compatibility  * ADD logic for max_words_count  * rename to max_words_per_line  * make them kwargs  * allow specifying file path by --model  * black formatting  ---------  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",165,168,Jordi Mas,b38a1f2,0,2023-11-06 09:49:33,2023-10-10 17:01:01
whisper/utils.py,6ed314f,amosal,"Add new option to generate subtitles by a specific number of words (#1729)  * ADD parser for new argument --max_words_count  * ADD max_words_count in words_options ADD warning for max_line_width compatibility  * ADD logic for max_words_count  * rename to max_words_per_line  * make them kwargs  * allow specifying file path by --model  * black formatting  ---------  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",149,163,Jordi Mas,b38a1f2,0,2023-11-06 09:49:33,2023-10-10 17:01:01
whisper/utils.py,43940fc,ryanheise,"Implement max line width and max line count, and make word highlighting optional (#1184)  * Add highlight_words, max_line_width, max_line_count  * Refactor subtitle generator  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",169,169,Local State,c6e4e5e,0,2023-04-11 00:28:35,2023-03-07 01:48:14
whisper/utils.py,43940fc,ryanheise,"Implement max line width and max line count, and make word highlighting optional (#1184)  * Add highlight_words, max_line_width, max_line_count  * Refactor subtitle generator  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",164,164,Local State,c6e4e5e,0,2023-04-11 00:28:35,2023-03-07 01:48:14
whisper/utils.py,6ed314f,amosal,"Add new option to generate subtitles by a specific number of words (#1729)  * ADD parser for new argument --max_words_count  * ADD max_words_count in words_options ADD warning for max_line_width compatibility  * ADD logic for max_words_count  * rename to max_words_per_line  * make them kwargs  * allow specifying file path by --model  * black formatting  ---------  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",170,192,Jordi Mas,b38a1f2,0,2023-11-06 09:49:33,2023-10-10 17:01:01
whisper/utils.py,43940fc,ryanheise,"Implement max line width and max line count, and make word highlighting optional (#1184)  * Add highlight_words, max_line_width, max_line_count  * Refactor subtitle generator  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",193,195,Local State,c6e4e5e,0,2023-04-11 00:28:35,2023-03-07 01:48:14
whisper/utils.py,b38a1f2,Jordi Mas,Fix exception when an audio file with no speech is provided (#1396)  Co-authored-by: Jong Wook Kim <jongwook@openai.com>,196,196,Local State,c6e4e5e,1,2023-10-10 17:01:01,2023-03-07 01:48:14
whisper/utils.py,26a7cac,Christian Clauss,"pre-commit autoupdate && pre-commit run --all-files (#2484)  * pre-commit autoupdate && pre-commit run --all-files  * Black formatter needs a current version of Python",212,216,ryanheise,ba3f3cd,0,2025-01-04 09:02:18,2023-12-18 20:11:16
whisper/utils.py,43940fc,ryanheise,"Implement max line width and max line count, and make word highlighting optional (#1184)  * Add highlight_words, max_line_width, max_line_count  * Refactor subtitle generator  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",217,227,Local State,c6e4e5e,0,2023-04-11 00:28:35,2023-03-07 01:48:14
whisper/utils.py,43940fc,ryanheise,"Implement max line width and max line count, and make word highlighting optional (#1184)  * Add highlight_words, max_line_width, max_line_count  * Refactor subtitle generator  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",197,211,Local State,c6e4e5e,0,2023-04-11 00:28:35,2023-03-07 01:48:14
whisper/utils.py,da600ab,Aaryan YVS,"Added --output_format option (#333)  * Added --output option  --output option will help select the output files that will be generated.  Corrected the logic, which wrongly shows progress bar when verbose is set to False  * Changed output_files variable  * Changed back the tqdm verbose  * refactor output format handling  Co-authored-by: Jong Wook Kim <jongwook@openai.com> Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",239,239,,,0,2023-01-22 07:58:38,
whisper/utils.py,6ed314f,amosal,"Add new option to generate subtitles by a specific number of words (#1729)  * ADD parser for new argument --max_words_count  * ADD max_words_count in words_options ADD warning for max_line_width compatibility  * ADD logic for max_words_count  * rename to max_words_per_line  * make them kwargs  * allow specifying file path by --model  * black formatting  ---------  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",247,247,Jordi Mas,b38a1f2,0,2023-11-06 09:49:33,2023-10-10 17:01:01
whisper/utils.py,6ed314f,amosal,"Add new option to generate subtitles by a specific number of words (#1729)  * ADD parser for new argument --max_words_count  * ADD max_words_count in words_options ADD warning for max_line_width compatibility  * ADD logic for max_words_count  * rename to max_words_per_line  * make them kwargs  * allow specifying file path by --model  * black formatting  ---------  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",243,245,Jordi Mas,b38a1f2,0,2023-11-06 09:49:33,2023-10-10 17:01:01
whisper/utils.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",228,238,,,1,2023-03-06 22:00:49,
whisper/utils.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",240,240,,,1,2023-03-06 22:00:49,
whisper/utils.py,da600ab,Aaryan YVS,"Added --output_format option (#333)  * Added --output option  --output option will help select the output files that will be generated.  Corrected the logic, which wrongly shows progress bar when verbose is set to False  * Changed output_files variable  * Changed back the tqdm verbose  * refactor output format handling  Co-authored-by: Jong Wook Kim <jongwook@openai.com> Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",246,246,,,0,2023-01-22 07:58:38,
whisper/utils.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",241,241,,,1,2023-03-06 23:50:37,
whisper/utils.py,da600ab,Aaryan YVS,"Added --output_format option (#333)  * Added --output option  --output option will help select the output files that will be generated.  Corrected the logic, which wrongly shows progress bar when verbose is set to False  * Changed output_files variable  * Changed back the tqdm verbose  * refactor output format handling  Co-authored-by: Jong Wook Kim <jongwook@openai.com> Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",242,242,,,0,2023-01-22 07:58:38,
whisper/utils.py,da600ab,Aaryan YVS,"Added --output_format option (#333)  * Added --output option  --output option will help select the output files that will be generated.  Corrected the logic, which wrongly shows progress bar when verbose is set to False  * Changed output_files variable  * Changed back the tqdm verbose  * refactor output format handling  Co-authored-by: Jong Wook Kim <jongwook@openai.com> Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",249,250,,,0,2023-01-22 07:58:38,
whisper/utils.py,da600ab,Aaryan YVS,"Added --output_format option (#333)  * Added --output option  --output option will help select the output files that will be generated.  Corrected the logic, which wrongly shows progress bar when verbose is set to False  * Changed output_files variable  * Changed back the tqdm verbose  * refactor output format handling  Co-authored-by: Jong Wook Kim <jongwook@openai.com> Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",252,252,,,0,2023-01-22 07:58:38,
whisper/utils.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",251,251,,,1,2023-03-06 22:00:49,
whisper/utils.py,da600ab,Aaryan YVS,"Added --output_format option (#333)  * Added --output option  --output option will help select the output files that will be generated.  Corrected the logic, which wrongly shows progress bar when verbose is set to False  * Changed output_files variable  * Changed back the tqdm verbose  * refactor output format handling  Co-authored-by: Jong Wook Kim <jongwook@openai.com> Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",255,255,,,0,2023-01-22 07:58:38,
whisper/utils.py,6ed314f,amosal,"Add new option to generate subtitles by a specific number of words (#1729)  * ADD parser for new argument --max_words_count  * ADD max_words_count in words_options ADD warning for max_line_width compatibility  * ADD logic for max_words_count  * rename to max_words_per_line  * make them kwargs  * allow specifying file path by --model  * black formatting  ---------  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",256,258,Jordi Mas,b38a1f2,0,2023-11-06 09:49:33,2023-10-10 17:01:01
whisper/utils.py,6ed314f,amosal,"Add new option to generate subtitles by a specific number of words (#1729)  * ADD parser for new argument --max_words_count  * ADD max_words_count in words_options ADD warning for max_line_width compatibility  * ADD logic for max_words_count  * rename to max_words_per_line  * make them kwargs  * allow specifying file path by --model  * black formatting  ---------  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",260,260,Jordi Mas,b38a1f2,0,2023-11-06 09:49:33,2023-10-10 17:01:01
whisper/utils.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",248,248,,,1,2023-03-06 22:00:49,
whisper/utils.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",254,254,,,1,2023-03-06 23:50:37,
whisper/utils.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",253,253,,,1,2023-03-06 22:00:49,
whisper/utils.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",262,262,,,1,2023-03-06 22:00:49,
whisper/utils.py,f5bfe00,Niels Mayer,"Add TSV formatted output in transcript, using integer start/end times in milliseconds. (#228)  * Add CSV format output in transcript, containing lines of characters formatted like: <startTime-in-integer-milliseconds>, <endTime-in-integer-milliseconds>, <transcript-including-commas>  * for easier reading by spreadsheets importing CSV, the third  column of the CSV file is delimited by quotes, and any quote characters that might be in the transcript (which would interfere with parsing the third column as a string) are converted to ""''"".  * fix syntax error  * docstring edit  Co-authored-by: Jong Wook Kim <jongwook@openai.com> Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",275,276,,,1,2023-01-22 08:27:17,
whisper/utils.py,6ed314f,amosal,"Add new option to generate subtitles by a specific number of words (#1729)  * ADD parser for new argument --max_words_count  * ADD max_words_count in words_options ADD warning for max_line_width compatibility  * ADD logic for max_words_count  * rename to max_words_per_line  * make them kwargs  * allow specifying file path by --model  * black formatting  ---------  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",277,279,Jordi Mas,b38a1f2,0,2023-11-06 09:49:33,2023-10-10 17:01:01
whisper/utils.py,f5bfe00,Niels Mayer,"Add TSV formatted output in transcript, using integer start/end times in milliseconds. (#228)  * Add CSV format output in transcript, containing lines of characters formatted like: <startTime-in-integer-milliseconds>, <endTime-in-integer-milliseconds>, <transcript-including-commas>  * for easier reading by spreadsheets importing CSV, the third  column of the CSV file is delimited by quotes, and any quote characters that might be in the transcript (which would interfere with parsing the third column as a string) are converted to ""''"".  * fix syntax error  * docstring edit  Co-authored-by: Jong Wook Kim <jongwook@openai.com> Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",265,273,,,1,2023-01-22 08:27:17,
whisper/utils.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",282,284,,,1,2023-03-06 23:50:37,
whisper/utils.py,da600ab,Aaryan YVS,"Added --output_format option (#333)  * Added --output option  --output option will help select the output files that will be generated.  Corrected the logic, which wrongly shows progress bar when verbose is set to False  * Changed output_files variable  * Changed back the tqdm verbose  * refactor output format handling  Co-authored-by: Jong Wook Kim <jongwook@openai.com> Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",287,289,,,0,2023-01-22 07:58:38,
whisper/utils.py,f5bfe00,Niels Mayer,"Add TSV formatted output in transcript, using integer start/end times in milliseconds. (#228)  * Add CSV format output in transcript, containing lines of characters formatted like: <startTime-in-integer-milliseconds>, <endTime-in-integer-milliseconds>, <transcript-including-commas>  * for easier reading by spreadsheets importing CSV, the third  column of the CSV file is delimited by quotes, and any quote characters that might be in the transcript (which would interfere with parsing the third column as a string) are converted to ""''"".  * fix syntax error  * docstring edit  Co-authored-by: Jong Wook Kim <jongwook@openai.com> Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",280,281,,,1,2023-01-22 08:27:17,
whisper/utils.py,da600ab,Aaryan YVS,"Added --output_format option (#333)  * Added --output option  --output option will help select the output files that will be generated.  Corrected the logic, which wrongly shows progress bar when verbose is set to False  * Changed output_files variable  * Changed back the tqdm verbose  * refactor output format handling  Co-authored-by: Jong Wook Kim <jongwook@openai.com> Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",263,264,,,0,2023-01-22 07:58:38,
whisper/utils.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",274,274,,,1,2023-03-06 23:50:37,
whisper/utils.py,43940fc,ryanheise,"Implement max line width and max line count, and make word highlighting optional (#1184)  * Add highlight_words, max_line_width, max_line_count  * Refactor subtitle generator  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",259,259,,,0,2023-04-11 00:28:35,
whisper/utils.py,6ed314f,amosal,"Add new option to generate subtitles by a specific number of words (#1729)  * ADD parser for new argument --max_words_count  * ADD max_words_count in words_options ADD warning for max_line_width compatibility  * ADD logic for max_words_count  * rename to max_words_per_line  * make them kwargs  * allow specifying file path by --model  * black formatting  ---------  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",290,292,Jordi Mas,b38a1f2,0,2023-11-06 09:49:33,2023-10-10 17:01:01
whisper/utils.py,da600ab,Aaryan YVS,"Added --output_format option (#333)  * Added --output option  --output option will help select the output files that will be generated.  Corrected the logic, which wrongly shows progress bar when verbose is set to False  * Changed output_files variable  * Changed back the tqdm verbose  * refactor output format handling  Co-authored-by: Jong Wook Kim <jongwook@openai.com> Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",293,295,,,0,2023-01-22 07:58:38,
whisper/utils.py,f5bfe00,Niels Mayer,"Add TSV formatted output in transcript, using integer start/end times in milliseconds. (#228)  * Add CSV format output in transcript, containing lines of characters formatted like: <startTime-in-integer-milliseconds>, <endTime-in-integer-milliseconds>, <transcript-including-commas>  * for easier reading by spreadsheets importing CSV, the third  column of the CSV file is delimited by quotes, and any quote characters that might be in the transcript (which would interfere with parsing the third column as a string) are converted to ""''"".  * fix syntax error  * docstring edit  Co-authored-by: Jong Wook Kim <jongwook@openai.com> Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",285,286,,,1,2023-01-22 08:27:17,
whisper/utils.py,f5bfe00,Niels Mayer,"Add TSV formatted output in transcript, using integer start/end times in milliseconds. (#228)  * Add CSV format output in transcript, containing lines of characters formatted like: <startTime-in-integer-milliseconds>, <endTime-in-integer-milliseconds>, <transcript-including-commas>  * for easier reading by spreadsheets importing CSV, the third  column of the CSV file is delimited by quotes, and any quote characters that might be in the transcript (which would interfere with parsing the third column as a string) are converted to ""''"".  * fix syntax error  * docstring edit  Co-authored-by: Jong Wook Kim <jongwook@openai.com> Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",303,303,,,1,2023-01-22 08:27:17,
whisper/utils.py,da600ab,Aaryan YVS,"Added --output_format option (#333)  * Added --output option  --output option will help select the output files that will be generated.  Corrected the logic, which wrongly shows progress bar when verbose is set to False  * Changed output_files variable  * Changed back the tqdm verbose  * refactor output format handling  Co-authored-by: Jong Wook Kim <jongwook@openai.com> Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",304,309,,,0,2023-01-22 07:58:38,
whisper/utils.py,da600ab,Aaryan YVS,"Added --output_format option (#333)  * Added --output option  --output option will help select the output files that will be generated.  Corrected the logic, which wrongly shows progress bar when verbose is set to False  * Changed output_files variable  * Changed back the tqdm verbose  * refactor output format handling  Co-authored-by: Jong Wook Kim <jongwook@openai.com> Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",313,313,,,0,2023-01-22 07:58:38,
whisper/utils.py,43940fc,ryanheise,"Implement max line width and max line count, and make word highlighting optional (#1184)  * Add highlight_words, max_line_width, max_line_count  * Refactor subtitle generator  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",261,261,,,0,2023-04-11 00:28:35,
whisper/utils.py,da600ab,Aaryan YVS,"Added --output_format option (#333)  * Added --output option  --output option will help select the output files that will be generated.  Corrected the logic, which wrongly shows progress bar when verbose is set to False  * Changed output_files variable  * Changed back the tqdm verbose  * refactor output format handling  Co-authored-by: Jong Wook Kim <jongwook@openai.com> Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",299,302,,,0,2023-01-22 07:58:38,
whisper/utils.py,da600ab,Aaryan YVS,"Added --output_format option (#333)  * Added --output option  --output option will help select the output files that will be generated.  Corrected the logic, which wrongly shows progress bar when verbose is set to False  * Changed output_files variable  * Changed back the tqdm verbose  * refactor output format handling  Co-authored-by: Jong Wook Kim <jongwook@openai.com> Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",315,318,,,0,2023-01-22 07:58:38,
whisper/utils.py,43940fc,ryanheise,"Implement max line width and max line count, and make word highlighting optional (#1184)  * Add highlight_words, max_line_width, max_line_count  * Refactor subtitle generator  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",296,298,,,0,2023-04-11 00:28:35,
whisper/utils.py,6ed314f,amosal,"Add new option to generate subtitles by a specific number of words (#1729)  * ADD parser for new argument --max_words_count  * ADD max_words_count in words_options ADD warning for max_line_width compatibility  * ADD logic for max_words_count  * rename to max_words_per_line  * make them kwargs  * allow specifying file path by --model  * black formatting  ---------  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",314,314,,,0,2023-11-06 09:49:33,
whisper/utils.py,6ed314f,amosal,"Add new option to generate subtitles by a specific number of words (#1729)  * ADD parser for new argument --max_words_count  * ADD max_words_count in words_options ADD warning for max_line_width compatibility  * ADD logic for max_words_count  * rename to max_words_per_line  * make them kwargs  * allow specifying file path by --model  * black formatting  ---------  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",310,312,,,0,2023-11-06 09:49:33,
whisper/transcribe.py,6e3be77,Jong Wook Kim,initial commit,1,2,,,0,2022-09-21 16:09:43,
whisper/transcribe.py,b7d277a,Marco Zucconelli,"handling transcribe exceptions. (#1682)  * handling transcribe() exceptions.  * printing stacktrace  ---------  Co-authored-by: invalid <invalid@email.com> Co-authored-by: Jong Wook Kim <jongwook@nyu.edu> Co-authored-by: Jong Wook Kim <jongwook@openai.com>",3,3,amosal,6ed314f,0,2023-11-06 10:06:19,2023-11-06 09:49:33
whisper/transcribe.py,6e3be77,Jong Wook Kim,initial commit,10,10,,,0,2022-09-21 16:09:43,
whisper/transcribe.py,6e3be77,Jong Wook Kim,initial commit,4,4,,,0,2022-09-21 16:09:43,
whisper/transcribe.py,9e7e418,fatih,"add progress bar for transcribe loop (#100)  * add progress bar to transcribe loop  * improved warning message for English-only models  * add --condition_on_previous_text  * progressbar renames  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",9,9,Jong Wook Kim,5d8d3e7,0,2022-09-26 10:24:13,2022-09-25 12:16:08
whisper/transcribe.py,ba3f3cd,ryanheise,"Skip silence around hallucinations (#1838)  * Add clip_timestamps option  * Add hallucination_silence_threshold option  * Fix typing for python < 3.9  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",5,5,Jong Wook Kim,c5d4256,1,2023-12-18 20:11:16,2023-11-06 18:10:30
whisper/transcribe.py,6e3be77,Jong Wook Kim,initial commit,6,8,,,0,2022-09-21 16:09:43,
whisper/transcribe.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",11,14,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/transcribe.py,919a713,Jong Wook Kim,"attempt to fix the repetition/hallucination issue identified in #1046 (#1052)  * attempt to fix the repetition/hallucination issue identified in #1046  * zero-pad the audio instead of spectrogram  * formatting fix  * delete debug print",15,15,Jong Wook Kim,b80bcf6,1,2023-03-08 04:08:45,2023-03-06 23:50:37
whisper/transcribe.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",23,25,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/transcribe.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",16,19,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/transcribe.py,6e3be77,Jong Wook Kim,initial commit,20,20,,,0,2022-09-21 16:09:43,
whisper/transcribe.py,ba3f3cd,ryanheise,"Skip silence around hallucinations (#1838)  * Add clip_timestamps option  * Add hallucination_silence_threshold option  * Fix typing for python < 3.9  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",26,26,Jong Wook Kim,c5d4256,1,2023-12-18 20:11:16,2023-11-06 18:10:30
whisper/transcribe.py,6e3be77,Jong Wook Kim,initial commit,22,22,,,0,2022-09-21 16:09:43,
whisper/transcribe.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",27,32,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/transcribe.py,b4308c4,Nick Konovalchuk,fix: transcribe verbosity (#140),42,42,VulumeCode,2037b65,1,2022-09-26 18:46:21,2022-09-26 12:22:33
whisper/transcribe.py,6e3be77,Jong Wook Kim,initial commit,33,41,,,0,2022-09-21 16:09:43,
whisper/transcribe.py,6e3be77,Jong Wook Kim,initial commit,43,45,,,0,2022-09-21 16:09:43,
whisper/transcribe.py,5979f03,kittsil,"Add option to carry initial_prompt with the sliding window (#2343)  * Add option to carry initial_prompt with the sliding window  Add an option `carry_initial_prompt = False` to `whisper.transcribe()`. When set to `True`, `initial_prompt` is prepended to each internal `decode()` call's `prompt`. If there is not enough context space at the start of the prompt, the prompt is left-sliced to make space.  * Prevent redundant initial_prompt_tokens  * Revert unnecessary .gitignore change  ---------  Co-authored-by: Kittsil <kittsil@gmail.com> Co-authored-by: Jong Wook Kim <jongwook@openai.com>",49,49,Jong Wook Kim,25e5c36,0,2024-10-26 14:17:31,2024-09-30 17:59:51
whisper/transcribe.py,5d8d3e7,Jong Wook Kim,add --condition_on_previous_text,47,47,,,0,2022-09-25 12:16:08,
whisper/transcribe.py,a6b36ed,Jong Wook Kim,drop python 3.7 support (#889),48,48,Jong Wook Kim,02aa851,0,2023-01-24 22:05:57,2022-11-16 00:25:11
whisper/transcribe.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",51,52,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/transcribe.py,15ab548,Jong Wook Kim,nocaptions -> nospeech to match the paper figure,46,46,,,0,2022-09-23 06:45:32,
whisper/transcribe.py,6e3be77,Jong Wook Kim,initial commit,55,68,,,0,2022-09-21 16:09:43,
whisper/transcribe.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",21,21,VulumeCode,2037b65,1,2023-03-06 22:00:49,2022-09-26 12:22:33
whisper/transcribe.py,ba3f3cd,ryanheise,"Skip silence around hallucinations (#1838)  * Add clip_timestamps option  * Add hallucination_silence_threshold option  * Fix typing for python < 3.9  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",53,54,Jong Wook Kim,c5d4256,1,2023-12-18 20:11:16,2023-11-06 18:10:30
whisper/transcribe.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",50,50,Jong Wook Kim,02aa851,1,2023-03-06 22:00:49,2022-11-16 00:25:11
whisper/transcribe.py,6e3be77,Jong Wook Kim,initial commit,74,81,,,0,2022-09-21 16:09:43,
whisper/transcribe.py,6e3be77,Jong Wook Kim,initial commit,71,72,,,0,2022-09-21 16:09:43,
whisper/transcribe.py,b4308c4,Nick Konovalchuk,fix: transcribe verbosity (#140),69,70,,,1,2022-09-26 18:46:21,
whisper/transcribe.py,15ab548,Jong Wook Kim,nocaptions -> nospeech to match the paper figure,82,83,,,0,2022-09-23 06:45:32,
whisper/transcribe.py,5d8d3e7,Jong Wook Kim,add --condition_on_previous_text,86,90,,,0,2022-09-25 12:16:08,
whisper/transcribe.py,5979f03,kittsil,"Add option to carry initial_prompt with the sliding window (#2343)  * Add option to carry initial_prompt with the sliding window  Add an option `carry_initial_prompt = False` to `whisper.transcribe()`. When set to `True`, `initial_prompt` is prepended to each internal `decode()` call's `prompt`. If there is not enough context space at the start of the prompt, the prompt is left-sliced to make space.  * Prevent redundant initial_prompt_tokens  * Revert unnecessary .gitignore change  ---------  Co-authored-by: Kittsil <kittsil@gmail.com> Co-authored-by: Jong Wook Kim <jongwook@openai.com>",106,110,Jong Wook Kim,25e5c36,0,2024-10-26 14:17:31,2024-09-30 17:59:51
whisper/transcribe.py,6e3be77,Jong Wook Kim,initial commit,84,85,,,0,2022-09-21 16:09:43,
whisper/transcribe.py,6e3be77,Jong Wook Kim,initial commit,122,137,,,0,2022-09-21 16:09:43,
whisper/transcribe.py,ba3f3cd,ryanheise,"Skip silence around hallucinations (#1838)  * Add clip_timestamps option  * Add hallucination_silence_threshold option  * Fix typing for python < 3.9  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",114,121,Jong Wook Kim,c5d4256,1,2023-12-18 20:11:16,2023-11-06 18:10:30
whisper/transcribe.py,919a713,Jong Wook Kim,"attempt to fix the repetition/hallucination issue identified in #1046 (#1052)  * attempt to fix the repetition/hallucination issue identified in #1046  * zero-pad the audio instead of spectrogram  * formatting fix  * delete debug print",138,138,Jong Wook Kim,500d0fe,1,2023-03-08 04:08:45,2023-03-06 22:00:49
whisper/transcribe.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",91,105,eudoxos,35713c6,1,2023-03-06 22:00:49,2022-10-09 09:11:15
whisper/transcribe.py,6e3be77,Jong Wook Kim,initial commit,111,113,,,0,2022-09-21 16:09:43,
whisper/transcribe.py,919a713,Jong Wook Kim,"attempt to fix the repetition/hallucination issue identified in #1046 (#1052)  * attempt to fix the repetition/hallucination issue identified in #1046  * zero-pad the audio instead of spectrogram  * formatting fix  * delete debug print",140,140,Jong Wook Kim,500d0fe,1,2023-03-08 04:08:45,2023-03-06 22:00:49
whisper/transcribe.py,70861c7,adamreis,"Fix tiny transcribe() docstring typo (#857)  s/successfully/successively, which I believe was the intent.",73,73,,,1,2023-01-17 06:42:01,
whisper/transcribe.py,6e3be77,Jong Wook Kim,initial commit,142,143,,,0,2022-09-21 16:09:43,
whisper/transcribe.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",148,150,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/transcribe.py,d18e9ea,Jong Wook Kim,"transcribe() on English-only model won't complain when language=""en"" is not given",144,147,EliEron,fc0f409,0,2022-10-09 09:40:12,2022-09-26 11:52:28
whisper/transcribe.py,d18e9ea,Jong Wook Kim,"transcribe() on English-only model won't complain when language=""en"" is not given",153,154,,,0,2022-10-09 09:40:12,
whisper/transcribe.py,6e3be77,Jong Wook Kim,initial commit,158,158,,,0,2022-09-21 16:09:43,
whisper/transcribe.py,6e3be77,Jong Wook Kim,initial commit,167,167,,,0,2022-09-21 16:09:43,
whisper/transcribe.py,ba3f3cd,ryanheise,"Skip silence around hallucinations (#1838)  * Add clip_timestamps option  * Add hallucination_silence_threshold option  * Fix typing for python < 3.9  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",141,141,Jong Wook Kim,500d0fe,1,2023-12-18 20:11:16,2023-03-06 22:00:49
whisper/transcribe.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",151,152,Vicki Anand,2b0c297,1,2023-03-06 22:00:49,2022-09-29 19:27:48
whisper/transcribe.py,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",139,139,Jong Wook Kim,500d0fe,1,2023-11-06 18:10:30,2023-03-06 22:00:49
whisper/transcribe.py,ba3f3cd,ryanheise,"Skip silence around hallucinations (#1838)  * Add clip_timestamps option  * Add hallucination_silence_threshold option  * Fix typing for python < 3.9  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",168,180,Jong Wook Kim,c5d4256,1,2023-12-18 20:11:16,2023-11-06 18:10:30
whisper/transcribe.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",155,157,Vicki Anand,2b0c297,1,2023-03-06 23:50:37,2022-09-29 19:27:48
whisper/transcribe.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",181,183,Jong Wook Kim,eab8d92,1,2023-03-06 22:00:49,2023-03-06 19:32:32
whisper/transcribe.py,7cb4cc2,Jong Wook Kim,allowing nonzero initial temperature,184,184,Jong Wook Kim,5d8d3e7,0,2022-09-30 01:05:12,2022-09-25 12:16:08
whisper/transcribe.py,7cb4cc2,Jong Wook Kim,allowing nonzero initial temperature,208,208,Jong Wook Kim,5d8d3e7,0,2022-09-30 01:05:12,2022-09-25 12:16:08
whisper/transcribe.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",209,212,Jong Wook Kim,eab8d92,1,2023-03-06 23:50:37,2023-03-06 19:32:32
whisper/transcribe.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",204,207,Jong Wook Kim,eab8d92,1,2023-03-06 23:50:37,2023-03-06 19:32:32
whisper/transcribe.py,7cb4cc2,Jong Wook Kim,allowing nonzero initial temperature,213,213,Jong Wook Kim,5d8d3e7,0,2022-09-30 01:05:12,2022-09-25 12:16:08
whisper/transcribe.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",159,160,,,1,2023-03-06 22:00:49,
whisper/transcribe.py,7cb4cc2,Jong Wook Kim,allowing nonzero initial temperature,188,203,Jong Wook Kim,5d8d3e7,0,2022-09-30 01:05:12,2022-09-25 12:16:08
whisper/transcribe.py,6e3be77,Jong Wook Kim,initial commit,225,225,,,0,2022-09-21 16:09:43,
whisper/transcribe.py,90db0de,Purfview,"Bugfix: Illogical ""Avoid computing higher temperatures on no_speech"" (#1903)  * Bugfix: Illogical ""Avoid computing higher temperatures on no_speech""  Bugfix for https://github.com/openai/whisper/pull/1279  It's ""silence"" when decoding has failed due to `compression_ratio_threshold` too, when further down the code it's not ""silence"" anymore.  ""Silence"" should be only when decoding has failed due to `logprob_threshold`.  Like described there: https://github.com/openai/whisper/blob/8bc8860694949db53c42ba47ddc23786c2e02a8b/whisper/transcribe.py#L421  And in code there: https://github.com/openai/whisper/blob/8bc8860694949db53c42ba47ddc23786c2e02a8b/whisper/transcribe.py#L243-L251  * Fix if ""logprob_threshold=None""  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",217,218,kittsil,5979f03,1,2024-12-01 05:47:01,2024-10-26 14:17:31
whisper/transcribe.py,7cb4cc2,Jong Wook Kim,allowing nonzero initial temperature,221,224,Jong Wook Kim,62fe7f1,0,2022-09-30 01:05:12,2022-09-28 02:00:41
whisper/transcribe.py,e334ff1,Théo BOYER,"Avoid computing higher temperatures on no_speech segments (#1279)  * Avoid computing higher temperatures on no_speech  In decode_with_fallback, we compute higher temperatures in the case where compression_ratio is too high or avg_logprob is too low. But as the computation of no_speech_prob doens't depend on sampling, we can avoid computing higher temperatures if we detect in the first one that the no_speech condition is fulfilled  * Update transcribe.py  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",214,216,Jong Wook Kim,919a713,0,2023-05-05 00:02:36,2023-03-08 04:08:45
whisper/transcribe.py,6e3be77,Jong Wook Kim,initial commit,228,237,,,0,2022-09-21 16:09:43,
whisper/transcribe.py,5979f03,kittsil,"Add option to carry initial_prompt with the sliding window (#2343)  * Add option to carry initial_prompt with the sliding window  Add an option `carry_initial_prompt = False` to `whisper.transcribe()`. When set to `True`, `initial_prompt` is prepended to each internal `decode()` call's `prompt`. If there is not enough context space at the start of the prompt, the prompt is left-sliced to make space.  * Prevent redundant initial_prompt_tokens  * Revert unnecessary .gitignore change  ---------  Co-authored-by: Kittsil <kittsil@gmail.com> Co-authored-by: Jong Wook Kim <jongwook@openai.com>",238,238,Jong Wook Kim,25e5c36,0,2024-10-26 14:17:31,2024-09-30 17:59:51
whisper/transcribe.py,5979f03,kittsil,"Add option to carry initial_prompt with the sliding window (#2343)  * Add option to carry initial_prompt with the sliding window  Add an option `carry_initial_prompt = False` to `whisper.transcribe()`. When set to `True`, `initial_prompt` is prepended to each internal `decode()` call's `prompt`. If there is not enough context space at the start of the prompt, the prompt is left-sliced to make space.  * Prevent redundant initial_prompt_tokens  * Revert unnecessary .gitignore change  ---------  Co-authored-by: Kittsil <kittsil@gmail.com> Co-authored-by: Jong Wook Kim <jongwook@openai.com>",242,242,Jong Wook Kim,25e5c36,0,2024-10-26 14:17:31,2024-09-30 17:59:51
whisper/transcribe.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",246,247,Jong Wook Kim,a6b36ed,1,2023-03-06 22:00:49,2023-01-24 22:05:57
whisper/transcribe.py,6e3be77,Jong Wook Kim,initial commit,248,248,,,0,2022-09-21 16:09:43,
whisper/transcribe.py,a6b36ed,Jong Wook Kim,drop python 3.7 support (#889),239,241,Jong Wook Kim,5d8d3e7,0,2023-01-24 22:05:57,2022-09-25 12:16:08
whisper/transcribe.py,2037b65,VulumeCode,Context prompt (#128)  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>,245,245,EliEron,fc0f409,0,2022-09-26 12:22:33,2022-09-26 11:52:28
whisper/transcribe.py,38f2f4d,Jong Wook Kim,fix all_tokens handling that caused more repetitions and discrepancy in JSON (#1060),249,250,Jong Wook Kim,919a713,1,2023-03-08 23:34:07,2023-03-08 04:08:45
whisper/transcribe.py,a6b36ed,Jong Wook Kim,drop python 3.7 support (#889),243,244,Jong Wook Kim,5d8d3e7,0,2023-01-24 22:05:57,2022-09-25 12:16:08
whisper/transcribe.py,e334ff1,Théo BOYER,"Avoid computing higher temperatures on no_speech segments (#1279)  * Avoid computing higher temperatures on no_speech  In decode_with_fallback, we compute higher temperatures in the case where compression_ratio is too high or avg_logprob is too low. But as the computation of no_speech_prob doens't depend on sampling, we can avoid computing higher temperatures if we detect in the first one that the no_speech condition is fulfilled  * Update transcribe.py  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",219,220,Jong Wook Kim,b80bcf6,0,2023-05-05 00:02:36,2023-03-06 23:50:37
whisper/transcribe.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",251,251,Jong Wook Kim,eab8d92,1,2023-03-06 22:00:49,2023-03-06 19:32:32
whisper/transcribe.py,919a713,Jong Wook Kim,"attempt to fix the repetition/hallucination issue identified in #1046 (#1052)  * attempt to fix the repetition/hallucination issue identified in #1046  * zero-pad the audio instead of spectrogram  * formatting fix  * delete debug print",265,265,Jong Wook Kim,b80bcf6,1,2023-03-08 04:08:45,2023-03-06 23:50:37
whisper/transcribe.py,38f2f4d,Jong Wook Kim,fix all_tokens handling that caused more repetitions and discrepancy in JSON (#1060),256,256,Jong Wook Kim,b80bcf6,1,2023-03-08 23:34:07,2023-03-06 23:50:37
whisper/transcribe.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",257,263,Jong Wook Kim,eab8d92,1,2023-03-06 22:00:49,2023-03-06 19:32:32
whisper/transcribe.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",252,255,Jong Wook Kim,eab8d92,1,2023-03-06 22:00:49,2023-03-06 19:32:32
whisper/transcribe.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",185,187,,,1,2023-03-06 23:50:37,
whisper/transcribe.py,c5d4256,Jong Wook Kim,"large-v3 (#1761)  * mel_filters() loads 128 mel bins  * can load 100-language models  * large-v3 checkpoint and evals  * add mandarin alias  * remove unused path  * flake8 fix  * formatting fix",161,166,Vicki Anand,2b0c297,1,2023-11-06 18:10:30,2022-09-29 19:27:48
whisper/transcribe.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",264,264,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/transcribe.py,ba3f3cd,ryanheise,"Skip silence around hallucinations (#1838)  * Add clip_timestamps option  * Add hallucination_silence_threshold option  * Fix typing for python < 3.9  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",268,280,Jong Wook Kim,c5d4256,1,2023-12-18 20:11:16,2023-11-06 18:10:30
whisper/transcribe.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",266,266,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/transcribe.py,ba3f3cd,ryanheise,"Skip silence around hallucinations (#1838)  * Add clip_timestamps option  * Add hallucination_silence_threshold option  * Fix typing for python < 3.9  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",226,227,Jong Wook Kim,7f1ef22,1,2023-12-18 20:11:16,2023-01-24 18:12:04
whisper/transcribe.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",281,281,Jong Wook Kim,eab8d92,1,2023-03-06 22:00:49,2023-03-06 19:32:32
whisper/transcribe.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",285,286,Jong Wook Kim,eab8d92,1,2023-03-06 22:00:49,2023-03-06 19:32:32
whisper/transcribe.py,f572f21,ryanheise,"Improve timestamp heuristics. (#1461)  * Improve timestamp heuristics.  * Track pauses with last_speech_timestamp",267,267,Jong Wook Kim,b80bcf6,0,2023-06-29 23:51:24,2023-03-06 23:50:37
whisper/transcribe.py,5979f03,kittsil,"Add option to carry initial_prompt with the sliding window (#2343)  * Add option to carry initial_prompt with the sliding window  Add an option `carry_initial_prompt = False` to `whisper.transcribe()`. When set to `True`, `initial_prompt` is prepended to each internal `decode()` call's `prompt`. If there is not enough context space at the start of the prompt, the prompt is left-sliced to make space.  * Prevent redundant initial_prompt_tokens  * Revert unnecessary .gitignore change  ---------  Co-authored-by: Kittsil <kittsil@gmail.com> Co-authored-by: Jong Wook Kim <jongwook@openai.com>",288,294,Jong Wook Kim,25e5c36,0,2024-10-26 14:17:31,2024-09-30 17:59:51
whisper/transcribe.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",295,295,Jong Wook Kim,eab8d92,1,2023-03-06 22:00:49,2023-03-06 19:32:32
whisper/transcribe.py,9e7e418,fatih,"add progress bar for transcribe loop (#100)  * add progress bar to transcribe loop  * improved warning message for English-only models  * add --condition_on_previous_text  * progressbar renames  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",287,287,hanacchi,c85eaaa,0,2022-09-26 10:24:13,2022-09-23 03:10:55
whisper/transcribe.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",301,304,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/transcribe.py,9e7e418,fatih,"add progress bar for transcribe loop (#100)  * add progress bar to transcribe loop  * improved warning message for English-only models  * add --condition_on_previous_text  * progressbar renames  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",310,311,,,0,2022-09-26 10:24:13,
whisper/transcribe.py,9e7e418,fatih,"add progress bar for transcribe loop (#100)  * add progress bar to transcribe loop  * improved warning message for English-only models  * add --condition_on_previous_text  * progressbar renames  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",305,308,,,0,2022-09-26 10:24:13,
whisper/transcribe.py,9e7e418,fatih,"add progress bar for transcribe loop (#100)  * add progress bar to transcribe loop  * improved warning message for English-only models  * add --condition_on_previous_text  * progressbar renames  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",296,300,EliEron,759e8d4,0,2022-09-26 10:24:13,2022-09-23 02:38:37
whisper/transcribe.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",314,314,Aaryan YVS,da600ab,1,2023-03-06 22:00:49,2023-01-22 07:58:38
whisper/transcribe.py,9e7e418,fatih,"add progress bar for transcribe loop (#100)  * add progress bar to transcribe loop  * improved warning message for English-only models  * add --condition_on_previous_text  * progressbar renames  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",339,339,,,0,2022-09-26 10:24:13,
whisper/transcribe.py,919a713,Jong Wook Kim,"attempt to fix the repetition/hallucination issue identified in #1046 (#1052)  * attempt to fix the repetition/hallucination issue identified in #1046  * zero-pad the audio instead of spectrogram  * formatting fix  * delete debug print",340,348,Jong Wook Kim,eab8d92,1,2023-03-08 04:08:45,2023-03-06 19:32:32
whisper/transcribe.py,ba3f3cd,ryanheise,"Skip silence around hallucinations (#1838)  * Add clip_timestamps option  * Add hallucination_silence_threshold option  * Fix typing for python < 3.9  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",315,338,Jong Wook Kim,c5d4256,1,2023-12-18 20:11:16,2023-11-06 18:10:30
whisper/transcribe.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",349,349,Jong Wook Kim,12e1089,1,2023-03-06 22:00:49,2023-01-20 08:54:05
whisper/transcribe.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",312,313,Jong Wook Kim,7cb4cc2,1,2023-03-06 22:00:49,2022-09-30 01:05:12
whisper/transcribe.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",353,366,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/transcribe.py,9e7e418,fatih,"add progress bar for transcribe loop (#100)  * add progress bar to transcribe loop  * improved warning message for English-only models  * add --condition_on_previous_text  * progressbar renames  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",352,352,,,0,2022-09-26 10:24:13,
whisper/transcribe.py,919a713,Jong Wook Kim,"attempt to fix the repetition/hallucination issue identified in #1046 (#1052)  * attempt to fix the repetition/hallucination issue identified in #1046  * zero-pad the audio instead of spectrogram  * formatting fix  * delete debug print",351,351,Jong Wook Kim,500d0fe,1,2023-03-08 04:08:45,2023-03-06 22:00:49
whisper/transcribe.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",368,368,Jong Wook Kim,7f1ef22,1,2023-03-06 22:00:49,2023-01-24 18:12:04
whisper/transcribe.py,9e7e418,fatih,"add progress bar for transcribe loop (#100)  * add progress bar to transcribe loop  * improved warning message for English-only models  * add --condition_on_previous_text  * progressbar renames  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",350,350,,,0,2022-09-26 10:24:13,
whisper/transcribe.py,ba3f3cd,ryanheise,"Skip silence around hallucinations (#1838)  * Add clip_timestamps option  * Add hallucination_silence_threshold option  * Fix typing for python < 3.9  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",282,284,Jong Wook Kim,500d0fe,1,2023-12-18 20:11:16,2023-03-06 22:00:49
whisper/transcribe.py,9e7e418,fatih,"add progress bar for transcribe loop (#100)  * add progress bar to transcribe loop  * improved warning message for English-only models  * add --condition_on_previous_text  * progressbar renames  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",367,367,,,0,2022-09-26 10:24:13,
whisper/transcribe.py,919a713,Jong Wook Kim,"attempt to fix the repetition/hallucination issue identified in #1046 (#1052)  * attempt to fix the repetition/hallucination issue identified in #1046  * zero-pad the audio instead of spectrogram  * formatting fix  * delete debug print",369,369,Jong Wook Kim,500d0fe,1,2023-03-08 04:08:45,2023-03-06 22:00:49
whisper/transcribe.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",371,371,Jong Wook Kim,7f1ef22,1,2023-03-06 22:00:49,2023-01-24 18:12:04
whisper/transcribe.py,9e7e418,fatih,"add progress bar for transcribe loop (#100)  * add progress bar to transcribe loop  * improved warning message for English-only models  * add --condition_on_previous_text  * progressbar renames  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",378,380,,,0,2022-09-26 10:24:13,
whisper/transcribe.py,9e7e418,fatih,"add progress bar for transcribe loop (#100)  * add progress bar to transcribe loop  * improved warning message for English-only models  * add --condition_on_previous_text  * progressbar renames  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",385,385,,,0,2022-09-26 10:24:13,
whisper/transcribe.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",381,384,Aaryan YVS,da600ab,1,2023-03-06 23:50:37,2023-01-22 07:58:38
whisper/transcribe.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",374,376,Jong Wook Kim,500d0fe,1,2023-03-06 23:50:37,2023-03-06 22:00:49
whisper/transcribe.py,eab8d92,Jong Wook Kim,"Decoding improvements (#1033)  * suppress task tokens (transcribe/translate)  * not ignoring the last segment ending with one timestamp",370,370,,,0,2023-03-06 19:32:32,
whisper/transcribe.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",309,309,,,1,2023-03-06 22:00:49,
whisper/transcribe.py,9e7e418,fatih,"add progress bar for transcribe loop (#100)  * add progress bar to transcribe loop  * improved warning message for English-only models  * add --condition_on_previous_text  * progressbar renames  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",390,390,,,0,2022-09-26 10:24:13,
whisper/transcribe.py,eab8d92,Jong Wook Kim,"Decoding improvements (#1033)  * suppress task tokens (transcribe/translate)  * not ignoring the last segment ending with one timestamp",372,373,,,0,2023-03-06 19:32:32,
whisper/transcribe.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",391,398,Jong Wook Kim,eab8d92,1,2023-03-06 23:50:37,2023-03-06 19:32:32
whisper/transcribe.py,eab8d92,Jong Wook Kim,"Decoding improvements (#1033)  * suppress task tokens (transcribe/translate)  * not ignoring the last segment ending with one timestamp",389,389,,,0,2023-03-06 19:32:32,
whisper/transcribe.py,f572f21,ryanheise,"Improve timestamp heuristics. (#1461)  * Improve timestamp heuristics.  * Track pauses with last_speech_timestamp",410,410,Jong Wook Kim,38f2f4d,0,2023-06-29 23:51:24,2023-03-08 23:34:07
whisper/transcribe.py,9e7e418,fatih,"add progress bar for transcribe loop (#100)  * add progress bar to transcribe loop  * improved warning message for English-only models  * add --condition_on_previous_text  * progressbar renames  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",400,400,,,0,2022-09-26 10:24:13,
whisper/transcribe.py,eab8d92,Jong Wook Kim,"Decoding improvements (#1033)  * suppress task tokens (transcribe/translate)  * not ignoring the last segment ending with one timestamp",377,377,,,0,2023-03-06 19:32:32,
whisper/transcribe.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",386,388,Jibin Mathew,0b1ba3d,1,2023-03-06 23:50:37,2022-09-30 21:45:51
whisper/transcribe.py,ba3f3cd,ryanheise,"Skip silence around hallucinations (#1838)  * Add clip_timestamps option  * Add hallucination_silence_threshold option  * Fix typing for python < 3.9  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",412,476,Jong Wook Kim,c5d4256,1,2023-12-18 20:11:16,2023-11-06 18:10:30
whisper/transcribe.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",401,409,,,1,2023-03-06 22:00:49,
whisper/transcribe.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",490,490,,,1,2023-03-06 22:00:49,
whisper/transcribe.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",399,399,,,1,2023-03-06 22:00:49,
whisper/transcribe.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",477,489,,,1,2023-03-06 22:00:49,
whisper/transcribe.py,9e7e418,fatih,"add progress bar for transcribe loop (#100)  * add progress bar to transcribe loop  * improved warning message for English-only models  * add --condition_on_previous_text  * progressbar renames  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",507,507,,,0,2022-09-26 10:24:13,
whisper/transcribe.py,38f2f4d,Jong Wook Kim,fix all_tokens handling that caused more repetitions and discrepancy in JSON (#1060),500,500,,,1,2023-03-08 23:34:07,
whisper/transcribe.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",501,501,,,1,2023-03-06 23:50:37,
whisper/transcribe.py,38f2f4d,Jong Wook Kim,fix all_tokens handling that caused more repetitions and discrepancy in JSON (#1060),491,498,,,1,2023-03-08 23:34:07,
whisper/transcribe.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",411,411,,,1,2023-03-06 22:00:49,
whisper/transcribe.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",502,502,,,1,2023-03-06 22:00:49,
whisper/transcribe.py,6e3be77,Jong Wook Kim,initial commit,509,509,,,0,2022-09-21 16:09:43,
whisper/transcribe.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",499,499,,,1,2023-03-06 23:50:37,
whisper/transcribe.py,919a713,Jong Wook Kim,"attempt to fix the repetition/hallucination issue identified in #1046 (#1052)  * attempt to fix the repetition/hallucination issue identified in #1046  * zero-pad the audio instead of spectrogram  * formatting fix  * delete debug print",508,508,,,1,2023-03-08 04:08:45,
whisper/transcribe.py,6e3be77,Jong Wook Kim,initial commit,515,519,,,0,2022-09-21 16:09:43,
whisper/transcribe.py,a6b36ed,Jong Wook Kim,drop python 3.7 support (#889),514,514,,,0,2023-01-24 22:05:57,
whisper/transcribe.py,a6b36ed,Jong Wook Kim,drop python 3.7 support (#889),510,510,,,0,2023-01-24 22:05:57,
whisper/transcribe.py,6e3be77,Jong Wook Kim,initial commit,528,529,,,0,2022-09-21 16:09:43,
whisper/transcribe.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",511,511,,,1,2023-03-06 23:50:37,
whisper/transcribe.py,a6b36ed,Jong Wook Kim,drop python 3.7 support (#889),512,512,,,0,2023-01-24 22:05:57,
whisper/transcribe.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",513,513,,,1,2023-03-06 23:50:37,
whisper/transcribe.py,0b1ba3d,Jibin Mathew,"Add model_dir to arguments (#202)  * Add model_dir to arguments  * minor formatting change  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",531,531,,,0,2022-09-30 21:45:51,
whisper/transcribe.py,6e3be77,Jong Wook Kim,initial commit,532,533,,,0,2022-09-21 16:09:43,
whisper/transcribe.py,6e3be77,Jong Wook Kim,initial commit,536,537,,,0,2022-09-21 16:09:43,
whisper/transcribe.py,834f00a,Jong Wook Kim,making small model the default,538,538,,,0,2022-09-21 17:45:12,
whisper/transcribe.py,5d8d3e7,Jong Wook Kim,add --condition_on_previous_text,535,535,,,0,2022-09-25 12:16:08,
whisper/transcribe.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",527,527,,,1,2023-03-06 23:50:37,
whisper/transcribe.py,6e3be77,Jong Wook Kim,initial commit,539,542,,,0,2022-09-21 16:09:43,
whisper/transcribe.py,35713c6,eudoxos,"Add --threads option to transcribe (#278)  * Add --threads option to transcribe  Torch on CPU uses by default number_of_cores/2. This option allows to override this default.  * Update transcribe.py  Co-authored-by: Jong Wook Kim <ilikekjw@gmail.com>",544,544,,,0,2022-10-09 09:11:15,
whisper/transcribe.py,62fe7f1,Jong Wook Kim,patience definition to match the paper,543,543,,,0,2022-09-28 02:00:41,
whisper/transcribe.py,6e3be77,Jong Wook Kim,initial commit,545,546,,,0,2022-09-21 16:09:43,
whisper/transcribe.py,2037b65,VulumeCode,Context prompt (#128)  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>,547,547,,,0,2022-09-26 12:22:33,
whisper/transcribe.py,5979f03,kittsil,"Add option to carry initial_prompt with the sliding window (#2343)  * Add option to carry initial_prompt with the sliding window  Add an option `carry_initial_prompt = False` to `whisper.transcribe()`. When set to `True`, `initial_prompt` is prepended to each internal `decode()` call's `prompt`. If there is not enough context space at the start of the prompt, the prompt is left-sliced to make space.  * Prevent redundant initial_prompt_tokens  * Revert unnecessary .gitignore change  ---------  Co-authored-by: Kittsil <kittsil@gmail.com> Co-authored-by: Jong Wook Kim <jongwook@openai.com>",548,549,Jong Wook Kim,25e5c36,0,2024-10-26 14:17:31,2024-09-30 17:59:51
whisper/transcribe.py,248b6cb,Valentin Berkes,fix condition_on_previous_text (#1224)  prompt_reset_since is set before all_tokens is extended hence does not have the expected effect.,503,506,,,1,2023-05-05 07:31:35,
whisper/transcribe.py,6e3be77,Jong Wook Kim,initial commit,551,555,,,0,2022-09-21 16:09:43,
whisper/transcribe.py,15ab548,Jong Wook Kim,nocaptions -> nospeech to match the paper figure,556,556,,,0,2022-09-23 06:45:32,
whisper/transcribe.py,5d8d3e7,Jong Wook Kim,add --condition_on_previous_text,550,550,,,0,2022-09-25 12:16:08,
whisper/transcribe.py,f5bfe00,Niels Mayer,"Add TSV formatted output in transcript, using integer start/end times in milliseconds. (#228)  * Add CSV format output in transcript, containing lines of characters formatted like: <startTime-in-integer-milliseconds>, <endTime-in-integer-milliseconds>, <transcript-including-commas>  * for easier reading by spreadsheets importing CSV, the third  column of the CSV file is delimited by quotes, and any quote characters that might be in the transcript (which would interfere with parsing the third column as a string) are converted to ""''"".  * fix syntax error  * docstring edit  Co-authored-by: Jong Wook Kim <jongwook@openai.com> Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",534,534,,,1,2023-01-22 08:27:17,
whisper/transcribe.py,35713c6,eudoxos,"Add --threads option to transcribe (#278)  * Add --threads option to transcribe  Torch on CPU uses by default number_of_cores/2. This option allows to override this default.  * Update transcribe.py  Co-authored-by: Jong Wook Kim <ilikekjw@gmail.com>",564,564,,,0,2022-10-09 09:11:15,
whisper/transcribe.py,25e5c36,Jong Wook Kim,large-v3-turbo model (#2361),530,530,Jibin Mathew,0b1ba3d,0,2024-09-30 17:59:51,2022-09-30 21:45:51
whisper/transcribe.py,6e3be77,Jong Wook Kim,initial commit,568,570,,,0,2022-09-21 16:09:43,
whisper/transcribe.py,0b1ba3d,Jibin Mathew,"Add model_dir to arguments (#202)  * Add model_dir to arguments  * minor formatting change  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",571,571,,,0,2022-09-30 21:45:51,
whisper/transcribe.py,500d0fe,Jong Wook Kim,"word-level timestamps in `transcribe()` (#869)  * word-level timestamps in `transcribe()`  * moving to `timing.py`  * numba implementation for dtw, replacing dtw-python  * triton implementation for dtw  * add test for dtw implementations  * triton implementation of median_filter  * a simple word-level timestamps test  * add scipy as dev dependency  * installs an older version of Triton if CUDA < 11.4  * fix broken merge  * loosen nvcc version match regex  * find_alignment() function  * miscellaneous improvements  * skip median filtering when the input is too small  * Expose punctuation options in cli and transcribe() (#973)  * fix merge error  * fix merge error 2  * annotating that word_timestamps is experimental  ---------  Co-authored-by: ryanheise <ryan@ryanheise.com>",557,559,,,1,2023-03-06 22:00:49,
whisper/transcribe.py,6e3be77,Jong Wook Kim,initial commit,572,572,,,0,2022-09-21 16:09:43,
whisper/transcribe.py,2d3032d,Jong Wook Kim,improved warning message for English-only models,577,577,,,0,2022-09-25 09:10:36,
whisper/transcribe.py,6e3be77,Jong Wook Kim,initial commit,574,576,,,0,2022-09-21 16:09:43,
whisper/transcribe.py,ba3f3cd,ryanheise,"Skip silence around hallucinations (#1838)  * Add clip_timestamps option  * Add hallucination_silence_threshold option  * Fix typing for python < 3.9  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",565,566,Jong Wook Kim,500d0fe,1,2023-12-18 20:11:16,2023-03-06 22:00:49
whisper/transcribe.py,d18e9ea,Jong Wook Kim,"transcribe() on English-only model won't complain when language=""en"" is not given",578,578,,,0,2022-10-09 09:40:12,
whisper/transcribe.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",567,567,,,1,2023-03-06 23:50:37,
whisper/transcribe.py,6ed314f,amosal,"Add new option to generate subtitles by a specific number of words (#1729)  * ADD parser for new argument --max_words_count  * ADD max_words_count in words_options ADD warning for max_line_width compatibility  * ADD logic for max_words_count  * rename to max_words_per_line  * make them kwargs  * allow specifying file path by --model  * black formatting  ---------  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",520,526,,,0,2023-11-06 09:49:33,
whisper/transcribe.py,da600ab,Aaryan YVS,"Added --output_format option (#333)  * Added --output option  --output option will help select the output files that will be generated.  Corrected the logic, which wrongly shows progress bar when verbose is set to False  * Changed output_files variable  * Changed back the tqdm verbose  * refactor output format handling  Co-authored-by: Jong Wook Kim <jongwook@openai.com> Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",573,573,,,0,2023-01-22 07:58:38,
whisper/transcribe.py,6e3be77,Jong Wook Kim,initial commit,582,583,,,0,2022-09-21 16:09:43,
whisper/transcribe.py,6e3be77,Jong Wook Kim,initial commit,587,589,,,0,2022-09-21 16:09:43,
whisper/transcribe.py,6e3be77,Jong Wook Kim,initial commit,584,584,,,0,2022-09-21 16:09:43,
whisper/transcribe.py,35713c6,eudoxos,"Add --threads option to transcribe (#278)  * Add --threads option to transcribe  Torch on CPU uses by default number_of_cores/2. This option allows to override this default.  * Update transcribe.py  Co-authored-by: Jong Wook Kim <ilikekjw@gmail.com>",591,592,,,0,2022-10-09 09:11:15,
whisper/transcribe.py,6e3be77,Jong Wook Kim,initial commit,593,593,,,0,2022-09-21 16:09:43,
whisper/transcribe.py,6e3be77,Jong Wook Kim,initial commit,596,596,,,0,2022-09-21 16:09:43,
whisper/transcribe.py,0b1ba3d,Jibin Mathew,"Add model_dir to arguments (#202)  * Add model_dir to arguments  * minor formatting change  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",595,595,,,0,2022-09-30 21:45:51,
whisper/transcribe.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",579,581,,,1,2023-03-06 23:50:37,
whisper/transcribe.py,a6b36ed,Jong Wook Kim,drop python 3.7 support (#889),585,586,,,0,2023-01-24 22:05:57,
whisper/transcribe.py,a6b36ed,Jong Wook Kim,drop python 3.7 support (#889),590,590,,,0,2023-01-24 22:05:57,
whisper/transcribe.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",594,594,,,1,2023-03-06 23:50:37,
whisper/transcribe.py,6e3be77,Jong Wook Kim,initial commit,613,613,,,0,2022-09-21 16:09:43,
whisper/transcribe.py,da600ab,Aaryan YVS,"Added --output_format option (#333)  * Added --output option  --output option will help select the output files that will be generated.  Corrected the logic, which wrongly shows progress bar when verbose is set to False  * Changed output_files variable  * Changed back the tqdm verbose  * refactor output format handling  Co-authored-by: Jong Wook Kim <jongwook@openai.com> Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",597,597,,,0,2023-01-22 07:58:38,
whisper/transcribe.py,ead77fa,fatih,"add srt subtitle export utility (#102)  * add srt subtitle export utility  * simplifying  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",620,620,,,0,2022-09-26 10:50:26,
whisper/transcribe.py,43940fc,ryanheise,"Implement max line width and max line count, and make word highlighting optional (#1184)  * Add highlight_words, max_line_width, max_line_count  * Refactor subtitle generator  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",560,562,,,0,2023-04-11 00:28:35,
whisper/transcribe.py,6e3be77,Jong Wook Kim,initial commit,621,621,,,0,2022-09-21 16:09:43,
whisper/transcribe.py,6e3be77,Jong Wook Kim,initial commit,623,623,,,0,2022-09-21 16:09:43,
whisper/transcribe.py,b80bcf6,Jong Wook Kim,"apply formatting with `black` (#1038)  * applying black (with the default 88-column limit)  * add flake8  * add isort  * fix isort",622,622,,,1,2023-03-06 23:50:37,
whisper/transcribe.py,6ed314f,amosal,"Add new option to generate subtitles by a specific number of words (#1729)  * ADD parser for new argument --max_words_count  * ADD max_words_count in words_options ADD warning for max_line_width compatibility  * ADD logic for max_words_count  * rename to max_words_per_line  * make them kwargs  * allow specifying file path by --model  * black formatting  ---------  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",563,563,,,0,2023-11-06 09:49:33,
whisper/transcribe.py,b7d277a,Marco Zucconelli,"handling transcribe exceptions. (#1682)  * handling transcribe() exceptions.  * printing stacktrace  ---------  Co-authored-by: invalid <invalid@email.com> Co-authored-by: Jong Wook Kim <jongwook@nyu.edu> Co-authored-by: Jong Wook Kim <jongwook@openai.com>",614,619,,,0,2023-11-06 10:06:19,
whisper/transcribe.py,43940fc,ryanheise,"Implement max line width and max line count, and make word highlighting optional (#1184)  * Add highlight_words, max_line_width, max_line_count  * Refactor subtitle generator  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",612,612,,,0,2023-04-11 00:28:35,
whisper/transcribe.py,43940fc,ryanheise,"Implement max line width and max line count, and make word highlighting optional (#1184)  * Add highlight_words, max_line_width, max_line_count  * Refactor subtitle generator  ---------  Co-authored-by: Jong Wook Kim <jongwook@openai.com>",604,609,,,0,2023-04-11 00:28:35,
whisper/transcribe.py,6ed314f,amosal,"Add new option to generate subtitles by a specific number of words (#1729)  * ADD parser for new argument --max_words_count  * ADD max_words_count in words_options ADD warning for max_line_width compatibility  * ADD logic for max_words_count  * rename to max_words_per_line  * make them kwargs  * allow specifying file path by --model  * black formatting  ---------  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",598,603,,,0,2023-11-06 09:49:33,
whisper/transcribe.py,6ed314f,amosal,"Add new option to generate subtitles by a specific number of words (#1729)  * ADD parser for new argument --max_words_count  * ADD max_words_count in words_options ADD warning for max_line_width compatibility  * ADD logic for max_words_count  * rename to max_words_per_line  * make them kwargs  * allow specifying file path by --model  * black formatting  ---------  Co-authored-by: Jong Wook Kim <jongwook@nyu.edu>",610,611,,,0,2023-11-06 09:49:33,
